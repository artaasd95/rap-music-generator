{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 7,
=======
   "execution_count": 1,
>>>>>>> 45d5d7512a259e119af2d0a0d1b085bad01865bc
   "metadata": {},
   "outputs": [],
   "source": [
    "import comet_ml\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, DataCollatorForLanguageModeling\n",
    "import datasets\n",
    "from transformers import logging, Trainer, TrainingArguments, DataCollatorForLanguageModeling\n",
    "from itertools import combinations\n",
    "import numpy as np\n",
    "import api_keys\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 8,
=======
   "execution_count": 2,
>>>>>>> 45d5d7512a259e119af2d0a0d1b085bad01865bc
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml Experiment Summary\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     name                  : poised_hamburger_607\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : https://www.comet.com/artaasd95/rap-lyrics-generator-llm/13404e1c0d7241b4baf92d2c6d045d77\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Parameters:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     num_train_epochs            : 3\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     per_device_train_batch_size : 2\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Uploads:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     environment details      : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     filename                 : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     git metadata             : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     git-patch (uncompressed) : 1 (519 bytes)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     installed packages       : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     notebook                 : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source_code              : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m \n",
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
<<<<<<< HEAD
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/artaasd95/rap-lyrics-generator-llm/cc4cab51aa9944e1a4e6f8dcd45a3d30\n",
=======
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/artaasd95/rap-lyrics-generator-llm/691a08178eb6451eb726ef00fac1e644\n",
>>>>>>> 45d5d7512a259e119af2d0a0d1b085bad01865bc
      "\n"
     ]
    }
   ],
   "source": [
    "experiment = comet_ml.Experiment(api_key=api_keys.comet, project_name='rap-lyrics-generator-llm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m Unknown error exporting current conda environment\n",
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m Unknown error retrieving Conda package as an explicit file\n",
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m Unknown error retrieving Conda information\n"
     ]
    }
   ],
   "source": [
    "experiment.log_parameters({\n",
<<<<<<< HEAD
    "    \"num_train_epochs\": 5,\n",
=======
    "    \"num_train_epochs\": 10,\n",
>>>>>>> 45d5d7512a259e119af2d0a0d1b085bad01865bc
    "    \"per_device_train_batch_size\": 2,\n",
    "    # Add any other relevant hyperparameters here\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rap_lyrics_train_dataset = datasets.load_dataset(\"nateraw/rap-lyrics-v2\", split='train')\n",
    "#rap_lyrics_train_dataset = rap_lyrics_train_dataset[:int(len(rap_lyrics_train_dataset)*0.7)]\n",
    "#rap_lyrics_test_dataset = datasets.load_dataset(\"nateraw/rap-lyrics-v2\", split='train')[int(len(rap_lyrics_train_dataset)*0.7):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Embedding(50258, 768)"
      ]
     },
<<<<<<< HEAD
     "execution_count": 15,
=======
     "execution_count": 5,
>>>>>>> 45d5d7512a259e119af2d0a0d1b085bad01865bc
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"gpt2\"  # You could use a larger model like gpt2-medium for better performance\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "model.resize_token_embeddings(len(tokenizer))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
<<<<<<< HEAD
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4a9fc8cda5a491ebff202f6c6b93797",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7319 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
=======
   "outputs": [],
>>>>>>> 45d5d7512a259e119af2d0a0d1b085bad01865bc
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['text'], truncation=True, padding=True, max_length=8092)\n",
    "\n",
    "# Tokenize dataset\n",
    "tokenized_train_dataset = rap_lyrics_train_dataset.map(tokenize_function, batched=True, remove_columns=[\"text\"])\n",
    "\n",
    "# Create a data collator for dynamic batching\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
    "\n",
    "# tokenized_test_dataset = rap_lyrics_train_dataset.map(tokenize_function, batched=True, remove_columns=[\"text\"])\n",
    "# data_collator_test = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m An experiment with the same configuration options is already running and will be reused.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
<<<<<<< HEAD
       "model_id": "db454c07c74e479dbf1275e61978f9dd",
=======
       "model_id": "2c8fb8d3a3c044f99561ca3fea789596",
>>>>>>> 45d5d7512a259e119af2d0a0d1b085bad01865bc
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
<<<<<<< HEAD
       "  0%|          | 0/18300 [00:00<?, ?it/s]"
=======
       "  0%|          | 0/36600 [00:00<?, ?it/s]"
>>>>>>> 45d5d7512a259e119af2d0a0d1b085bad01865bc
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "{'loss': 3.2603, 'grad_norm': 15.812793731689453, 'learning_rate': 4.9726775956284156e-05, 'epoch': 0.03}\n",
      "{'loss': 2.988, 'grad_norm': 11.727437019348145, 'learning_rate': 4.945355191256831e-05, 'epoch': 0.05}\n",
      "{'loss': 3.1803, 'grad_norm': 7.573428630828857, 'learning_rate': 4.918032786885246e-05, 'epoch': 0.08}\n"
     ]
=======
      "{'loss': 3.2603, 'grad_norm': 15.807796478271484, 'learning_rate': 4.986338797814208e-05, 'epoch': 0.03}\n",
      "{'loss': 2.988, 'grad_norm': 11.71533203125, 'learning_rate': 4.9726775956284156e-05, 'epoch': 0.05}\n",
      "{'loss': 3.1804, 'grad_norm': 7.549360752105713, 'learning_rate': 4.959016393442623e-05, 'epoch': 0.08}\n",
      "{'loss': 3.1781, 'grad_norm': 8.843524932861328, 'learning_rate': 4.945355191256831e-05, 'epoch': 0.11}\n",
      "{'loss': 3.16, 'grad_norm': 10.169281959533691, 'learning_rate': 4.9316939890710386e-05, 'epoch': 0.14}\n",
      "{'loss': 3.0272, 'grad_norm': 5.531196117401123, 'learning_rate': 4.918032786885246e-05, 'epoch': 0.16}\n",
      "{'loss': 2.994, 'grad_norm': 4.846259117126465, 'learning_rate': 4.904371584699454e-05, 'epoch': 0.19}\n",
      "{'loss': 3.1661, 'grad_norm': 7.918515682220459, 'learning_rate': 4.890710382513661e-05, 'epoch': 0.22}\n",
      "{'loss': 2.9809, 'grad_norm': 5.712575912475586, 'learning_rate': 4.8770491803278687e-05, 'epoch': 0.25}\n",
      "{'loss': 2.9997, 'grad_norm': 5.790170192718506, 'learning_rate': 4.863387978142076e-05, 'epoch': 0.27}\n",
      "{'loss': 3.0675, 'grad_norm': 4.356205463409424, 'learning_rate': 4.849726775956284e-05, 'epoch': 0.3}\n",
      "{'loss': 2.9455, 'grad_norm': 3.8813138008117676, 'learning_rate': 4.836065573770492e-05, 'epoch': 0.33}\n",
      "{'loss': 3.0403, 'grad_norm': 3.2392048835754395, 'learning_rate': 4.8224043715846994e-05, 'epoch': 0.36}\n",
      "{'loss': 2.9404, 'grad_norm': 3.930124044418335, 'learning_rate': 4.808743169398907e-05, 'epoch': 0.38}\n",
      "{'loss': 2.8591, 'grad_norm': 5.027572154998779, 'learning_rate': 4.795081967213115e-05, 'epoch': 0.41}\n",
      "{'loss': 2.9181, 'grad_norm': 3.30078125, 'learning_rate': 4.7814207650273224e-05, 'epoch': 0.44}\n",
      "{'loss': 2.872, 'grad_norm': 3.463669538497925, 'learning_rate': 4.76775956284153e-05, 'epoch': 0.46}\n",
      "{'loss': 2.8169, 'grad_norm': 4.517979621887207, 'learning_rate': 4.754098360655738e-05, 'epoch': 0.49}\n",
      "{'loss': 2.9593, 'grad_norm': 2.711411237716675, 'learning_rate': 4.740437158469946e-05, 'epoch': 0.52}\n",
      "{'loss': 2.8496, 'grad_norm': 3.452193260192871, 'learning_rate': 4.726775956284154e-05, 'epoch': 0.55}\n",
      "{'loss': 2.8388, 'grad_norm': 4.764568328857422, 'learning_rate': 4.713114754098361e-05, 'epoch': 0.57}\n",
      "{'loss': 2.7938, 'grad_norm': 3.323674440383911, 'learning_rate': 4.6994535519125685e-05, 'epoch': 0.6}\n",
      "{'loss': 2.8934, 'grad_norm': 6.306133270263672, 'learning_rate': 4.685792349726776e-05, 'epoch': 0.63}\n",
      "{'loss': 2.9102, 'grad_norm': 3.2335996627807617, 'learning_rate': 4.672131147540984e-05, 'epoch': 0.66}\n",
      "{'loss': 2.9289, 'grad_norm': 3.817958354949951, 'learning_rate': 4.6584699453551915e-05, 'epoch': 0.68}\n",
      "{'loss': 2.8671, 'grad_norm': 3.6392364501953125, 'learning_rate': 4.644808743169399e-05, 'epoch': 0.71}\n",
      "{'loss': 2.8929, 'grad_norm': 4.151871204376221, 'learning_rate': 4.631147540983607e-05, 'epoch': 0.74}\n",
      "{'loss': 2.7829, 'grad_norm': 2.7491424083709717, 'learning_rate': 4.6174863387978145e-05, 'epoch': 0.77}\n",
      "{'loss': 2.9108, 'grad_norm': 3.9332523345947266, 'learning_rate': 4.603825136612022e-05, 'epoch': 0.79}\n",
      "{'loss': 2.9401, 'grad_norm': 3.8712918758392334, 'learning_rate': 4.59016393442623e-05, 'epoch': 0.82}\n",
      "{'loss': 2.8717, 'grad_norm': 3.486823797225952, 'learning_rate': 4.5765027322404376e-05, 'epoch': 0.85}\n",
      "{'loss': 2.9759, 'grad_norm': 3.908604145050049, 'learning_rate': 4.562841530054645e-05, 'epoch': 0.87}\n",
      "{'loss': 2.7198, 'grad_norm': 3.057884693145752, 'learning_rate': 4.549180327868853e-05, 'epoch': 0.9}\n",
      "{'loss': 2.9357, 'grad_norm': 4.674871921539307, 'learning_rate': 4.5355191256830606e-05, 'epoch': 0.93}\n",
      "{'loss': 2.7401, 'grad_norm': 5.164212226867676, 'learning_rate': 4.521857923497268e-05, 'epoch': 0.96}\n",
      "{'loss': 2.8282, 'grad_norm': 3.280994176864624, 'learning_rate': 4.508196721311476e-05, 'epoch': 0.98}\n",
      "{'loss': 2.7062, 'grad_norm': 3.217897653579712, 'learning_rate': 4.494535519125683e-05, 'epoch': 1.01}\n",
      "{'loss': 2.5199, 'grad_norm': 3.6574063301086426, 'learning_rate': 4.4808743169398906e-05, 'epoch': 1.04}\n",
      "{'loss': 2.5992, 'grad_norm': 3.5443131923675537, 'learning_rate': 4.467213114754098e-05, 'epoch': 1.07}\n",
      "{'loss': 2.6699, 'grad_norm': 3.573765277862549, 'learning_rate': 4.453551912568306e-05, 'epoch': 1.09}\n",
      "{'loss': 2.6555, 'grad_norm': 2.9222795963287354, 'learning_rate': 4.4398907103825137e-05, 'epoch': 1.12}\n",
      "{'loss': 2.5957, 'grad_norm': 7.279341697692871, 'learning_rate': 4.426229508196721e-05, 'epoch': 1.15}\n",
      "{'loss': 2.6511, 'grad_norm': 3.613790273666382, 'learning_rate': 4.412568306010929e-05, 'epoch': 1.17}\n",
      "{'loss': 2.6195, 'grad_norm': 6.7068305015563965, 'learning_rate': 4.398907103825137e-05, 'epoch': 1.2}\n",
      "{'loss': 2.6419, 'grad_norm': 4.548233985900879, 'learning_rate': 4.3852459016393444e-05, 'epoch': 1.23}\n",
      "{'loss': 2.5011, 'grad_norm': 3.9178802967071533, 'learning_rate': 4.371584699453552e-05, 'epoch': 1.26}\n",
      "{'loss': 2.5259, 'grad_norm': 4.2289838790893555, 'learning_rate': 4.35792349726776e-05, 'epoch': 1.28}\n",
      "{'loss': 2.5732, 'grad_norm': 2.8835513591766357, 'learning_rate': 4.3442622950819674e-05, 'epoch': 1.31}\n",
      "{'loss': 2.6718, 'grad_norm': 4.659393310546875, 'learning_rate': 4.330601092896175e-05, 'epoch': 1.34}\n",
      "{'loss': 2.5375, 'grad_norm': 5.120795249938965, 'learning_rate': 4.316939890710383e-05, 'epoch': 1.37}\n",
      "{'loss': 2.6333, 'grad_norm': 4.226047992706299, 'learning_rate': 4.3032786885245904e-05, 'epoch': 1.39}\n",
      "{'loss': 2.5507, 'grad_norm': 3.279391050338745, 'learning_rate': 4.289617486338798e-05, 'epoch': 1.42}\n",
      "{'loss': 2.533, 'grad_norm': 3.4965741634368896, 'learning_rate': 4.275956284153005e-05, 'epoch': 1.45}\n",
      "{'loss': 2.4867, 'grad_norm': 3.4728548526763916, 'learning_rate': 4.262295081967213e-05, 'epoch': 1.48}\n",
      "{'loss': 2.6237, 'grad_norm': 5.132904052734375, 'learning_rate': 4.248633879781421e-05, 'epoch': 1.5}\n",
      "{'loss': 2.5148, 'grad_norm': 3.070265531539917, 'learning_rate': 4.234972677595629e-05, 'epoch': 1.53}\n",
      "{'loss': 2.5254, 'grad_norm': 6.892310619354248, 'learning_rate': 4.2213114754098365e-05, 'epoch': 1.56}\n",
      "{'loss': 2.5988, 'grad_norm': 6.1738128662109375, 'learning_rate': 4.207650273224044e-05, 'epoch': 1.58}\n",
      "{'loss': 2.6444, 'grad_norm': 4.489424228668213, 'learning_rate': 4.193989071038252e-05, 'epoch': 1.61}\n",
      "{'loss': 2.5499, 'grad_norm': 3.53836727142334, 'learning_rate': 4.1803278688524595e-05, 'epoch': 1.64}\n",
      "{'loss': 2.6463, 'grad_norm': 3.7672345638275146, 'learning_rate': 4.166666666666667e-05, 'epoch': 1.67}\n",
      "{'loss': 2.4587, 'grad_norm': 3.8045670986175537, 'learning_rate': 4.153005464480875e-05, 'epoch': 1.69}\n",
      "{'loss': 2.5113, 'grad_norm': 4.948604583740234, 'learning_rate': 4.1393442622950826e-05, 'epoch': 1.72}\n",
      "{'loss': 2.4813, 'grad_norm': 2.6489744186401367, 'learning_rate': 4.12568306010929e-05, 'epoch': 1.75}\n",
      "{'loss': 2.585, 'grad_norm': 3.5118207931518555, 'learning_rate': 4.112021857923498e-05, 'epoch': 1.78}\n",
      "{'loss': 2.5455, 'grad_norm': 3.526839256286621, 'learning_rate': 4.098360655737705e-05, 'epoch': 1.8}\n",
      "{'loss': 2.5589, 'grad_norm': 3.855915069580078, 'learning_rate': 4.0846994535519126e-05, 'epoch': 1.83}\n",
      "{'loss': 2.5517, 'grad_norm': 4.0496649742126465, 'learning_rate': 4.07103825136612e-05, 'epoch': 1.86}\n",
      "{'loss': 2.6126, 'grad_norm': 3.51802134513855, 'learning_rate': 4.057377049180328e-05, 'epoch': 1.89}\n",
      "{'loss': 2.6645, 'grad_norm': 2.4674980640411377, 'learning_rate': 4.0437158469945356e-05, 'epoch': 1.91}\n",
      "{'loss': 2.5693, 'grad_norm': 4.525042533874512, 'learning_rate': 4.030054644808743e-05, 'epoch': 1.94}\n",
      "{'loss': 2.5551, 'grad_norm': 3.813549757003784, 'learning_rate': 4.016393442622951e-05, 'epoch': 1.97}\n",
      "{'loss': 2.5402, 'grad_norm': 3.6687982082366943, 'learning_rate': 4.0027322404371587e-05, 'epoch': 1.99}\n",
      "{'loss': 2.433, 'grad_norm': 3.3073208332061768, 'learning_rate': 3.989071038251366e-05, 'epoch': 2.02}\n",
      "{'loss': 2.4458, 'grad_norm': 3.918226718902588, 'learning_rate': 3.975409836065574e-05, 'epoch': 2.05}\n",
      "{'loss': 2.3634, 'grad_norm': 4.874473571777344, 'learning_rate': 3.961748633879782e-05, 'epoch': 2.08}\n",
      "{'loss': 2.3037, 'grad_norm': 4.057857513427734, 'learning_rate': 3.9480874316939894e-05, 'epoch': 2.1}\n",
      "{'loss': 2.3669, 'grad_norm': 4.168609142303467, 'learning_rate': 3.934426229508197e-05, 'epoch': 2.13}\n",
      "{'loss': 2.1689, 'grad_norm': 2.532867670059204, 'learning_rate': 3.920765027322405e-05, 'epoch': 2.16}\n",
      "{'loss': 2.4732, 'grad_norm': 7.985013484954834, 'learning_rate': 3.9071038251366124e-05, 'epoch': 2.19}\n",
      "{'loss': 2.3589, 'grad_norm': 3.5274784564971924, 'learning_rate': 3.89344262295082e-05, 'epoch': 2.21}\n",
      "{'loss': 2.4378, 'grad_norm': 4.957995414733887, 'learning_rate': 3.879781420765027e-05, 'epoch': 2.24}\n",
      "{'loss': 2.3625, 'grad_norm': 4.419295787811279, 'learning_rate': 3.866120218579235e-05, 'epoch': 2.27}\n",
      "{'loss': 2.4175, 'grad_norm': 4.245720863342285, 'learning_rate': 3.8524590163934424e-05, 'epoch': 2.3}\n",
      "{'loss': 2.4381, 'grad_norm': 3.2670702934265137, 'learning_rate': 3.83879781420765e-05, 'epoch': 2.32}\n",
      "{'loss': 2.2555, 'grad_norm': 7.2625813484191895, 'learning_rate': 3.825136612021858e-05, 'epoch': 2.35}\n",
      "{'loss': 2.2773, 'grad_norm': 6.430990695953369, 'learning_rate': 3.8114754098360655e-05, 'epoch': 2.38}\n",
      "{'loss': 2.4444, 'grad_norm': 5.357091903686523, 'learning_rate': 3.797814207650273e-05, 'epoch': 2.4}\n",
      "{'loss': 2.3429, 'grad_norm': 3.971888542175293, 'learning_rate': 3.784153005464481e-05, 'epoch': 2.43}\n",
      "{'loss': 2.3, 'grad_norm': 7.043834686279297, 'learning_rate': 3.7704918032786885e-05, 'epoch': 2.46}\n",
      "{'loss': 2.3689, 'grad_norm': 4.916102409362793, 'learning_rate': 3.756830601092896e-05, 'epoch': 2.49}\n",
      "{'loss': 2.2598, 'grad_norm': 3.2956254482269287, 'learning_rate': 3.7431693989071045e-05, 'epoch': 2.51}\n",
      "{'loss': 2.2822, 'grad_norm': 4.327495574951172, 'learning_rate': 3.729508196721312e-05, 'epoch': 2.54}\n",
      "{'loss': 2.2839, 'grad_norm': 4.131680011749268, 'learning_rate': 3.71584699453552e-05, 'epoch': 2.57}\n",
      "{'loss': 2.3015, 'grad_norm': 7.993844032287598, 'learning_rate': 3.702185792349727e-05, 'epoch': 2.6}\n",
      "{'loss': 2.4996, 'grad_norm': 3.62103271484375, 'learning_rate': 3.6885245901639346e-05, 'epoch': 2.62}\n",
      "{'loss': 2.4327, 'grad_norm': 4.458857536315918, 'learning_rate': 3.674863387978142e-05, 'epoch': 2.65}\n",
      "{'loss': 2.2051, 'grad_norm': 3.139953374862671, 'learning_rate': 3.66120218579235e-05, 'epoch': 2.68}\n",
      "{'loss': 2.4473, 'grad_norm': 4.088296890258789, 'learning_rate': 3.6475409836065576e-05, 'epoch': 2.7}\n",
      "{'loss': 2.3988, 'grad_norm': 5.263258457183838, 'learning_rate': 3.633879781420765e-05, 'epoch': 2.73}\n",
      "{'loss': 2.2235, 'grad_norm': 3.3305320739746094, 'learning_rate': 3.620218579234973e-05, 'epoch': 2.76}\n",
      "{'loss': 2.2478, 'grad_norm': 4.492375373840332, 'learning_rate': 3.6065573770491806e-05, 'epoch': 2.79}\n",
      "{'loss': 2.2802, 'grad_norm': 3.4684877395629883, 'learning_rate': 3.592896174863388e-05, 'epoch': 2.81}\n",
      "{'loss': 2.3446, 'grad_norm': 2.9912242889404297, 'learning_rate': 3.579234972677596e-05, 'epoch': 2.84}\n",
      "{'loss': 2.2692, 'grad_norm': 4.0500712394714355, 'learning_rate': 3.5655737704918037e-05, 'epoch': 2.87}\n",
      "{'loss': 2.3743, 'grad_norm': 3.467200756072998, 'learning_rate': 3.551912568306011e-05, 'epoch': 2.9}\n",
      "{'loss': 2.3319, 'grad_norm': 3.772942066192627, 'learning_rate': 3.538251366120219e-05, 'epoch': 2.92}\n",
      "{'loss': 2.3131, 'grad_norm': 5.330801963806152, 'learning_rate': 3.524590163934427e-05, 'epoch': 2.95}\n",
      "{'loss': 2.2988, 'grad_norm': 3.7101058959960938, 'learning_rate': 3.5109289617486344e-05, 'epoch': 2.98}\n",
      "{'loss': 2.4078, 'grad_norm': 5.625675201416016, 'learning_rate': 3.4972677595628414e-05, 'epoch': 3.01}\n",
      "{'loss': 2.1776, 'grad_norm': 3.674241304397583, 'learning_rate': 3.483606557377049e-05, 'epoch': 3.03}\n",
      "{'loss': 2.1477, 'grad_norm': 4.649543285369873, 'learning_rate': 3.469945355191257e-05, 'epoch': 3.06}\n",
      "{'loss': 2.2005, 'grad_norm': 5.199044704437256, 'learning_rate': 3.4562841530054644e-05, 'epoch': 3.09}\n",
      "{'loss': 2.1342, 'grad_norm': 2.6863465309143066, 'learning_rate': 3.442622950819672e-05, 'epoch': 3.11}\n",
      "{'loss': 2.2204, 'grad_norm': 5.933119297027588, 'learning_rate': 3.42896174863388e-05, 'epoch': 3.14}\n",
      "{'loss': 2.1142, 'grad_norm': 5.207037925720215, 'learning_rate': 3.4153005464480874e-05, 'epoch': 3.17}\n",
      "{'loss': 2.1684, 'grad_norm': 4.009345054626465, 'learning_rate': 3.401639344262295e-05, 'epoch': 3.2}\n",
      "{'loss': 1.9692, 'grad_norm': 5.566800594329834, 'learning_rate': 3.387978142076503e-05, 'epoch': 3.22}\n",
      "{'loss': 2.184, 'grad_norm': 4.134400844573975, 'learning_rate': 3.3743169398907105e-05, 'epoch': 3.25}\n",
      "{'loss': 2.1556, 'grad_norm': 6.499380588531494, 'learning_rate': 3.360655737704918e-05, 'epoch': 3.28}\n",
      "{'loss': 2.2513, 'grad_norm': 4.432435512542725, 'learning_rate': 3.346994535519126e-05, 'epoch': 3.31}\n",
      "{'loss': 2.1856, 'grad_norm': 3.5773110389709473, 'learning_rate': 3.3333333333333335e-05, 'epoch': 3.33}\n",
      "{'loss': 2.1895, 'grad_norm': 5.360930919647217, 'learning_rate': 3.319672131147541e-05, 'epoch': 3.36}\n",
      "{'loss': 2.1534, 'grad_norm': 3.507814645767212, 'learning_rate': 3.306010928961749e-05, 'epoch': 3.39}\n",
      "{'loss': 2.109, 'grad_norm': 5.147380828857422, 'learning_rate': 3.2923497267759565e-05, 'epoch': 3.42}\n",
      "{'loss': 2.1992, 'grad_norm': 3.274214029312134, 'learning_rate': 3.2786885245901635e-05, 'epoch': 3.44}\n",
      "{'loss': 2.0289, 'grad_norm': 4.508609294891357, 'learning_rate': 3.265027322404371e-05, 'epoch': 3.47}\n",
      "{'loss': 2.1104, 'grad_norm': 3.807605504989624, 'learning_rate': 3.251366120218579e-05, 'epoch': 3.5}\n",
      "{'loss': 2.1575, 'grad_norm': 6.403694152832031, 'learning_rate': 3.237704918032787e-05, 'epoch': 3.52}\n",
      "{'loss': 2.0677, 'grad_norm': 3.858947992324829, 'learning_rate': 3.224043715846995e-05, 'epoch': 3.55}\n",
      "{'loss': 2.2744, 'grad_norm': 4.235976696014404, 'learning_rate': 3.2103825136612026e-05, 'epoch': 3.58}\n",
      "{'loss': 2.0872, 'grad_norm': 4.046511173248291, 'learning_rate': 3.19672131147541e-05, 'epoch': 3.61}\n",
      "{'loss': 2.2477, 'grad_norm': 7.2256178855896, 'learning_rate': 3.183060109289618e-05, 'epoch': 3.63}\n",
      "{'loss': 2.1219, 'grad_norm': 3.0025508403778076, 'learning_rate': 3.1693989071038256e-05, 'epoch': 3.66}\n",
      "{'loss': 2.1743, 'grad_norm': 3.6035213470458984, 'learning_rate': 3.155737704918033e-05, 'epoch': 3.69}\n",
      "{'loss': 2.0792, 'grad_norm': 4.781215190887451, 'learning_rate': 3.142076502732241e-05, 'epoch': 3.72}\n",
      "{'loss': 2.1941, 'grad_norm': 6.9796295166015625, 'learning_rate': 3.1284153005464487e-05, 'epoch': 3.74}\n",
      "{'loss': 2.1314, 'grad_norm': 5.1720051765441895, 'learning_rate': 3.114754098360656e-05, 'epoch': 3.77}\n",
      "{'loss': 2.0675, 'grad_norm': 7.383880138397217, 'learning_rate': 3.101092896174863e-05, 'epoch': 3.8}\n",
      "{'loss': 2.1379, 'grad_norm': 7.090941905975342, 'learning_rate': 3.087431693989071e-05, 'epoch': 3.83}\n",
      "{'loss': 2.1631, 'grad_norm': 3.9431958198547363, 'learning_rate': 3.073770491803279e-05, 'epoch': 3.85}\n",
      "{'loss': 2.2144, 'grad_norm': 4.7780022621154785, 'learning_rate': 3.0601092896174864e-05, 'epoch': 3.88}\n",
      "{'loss': 2.2556, 'grad_norm': 3.660658121109009, 'learning_rate': 3.046448087431694e-05, 'epoch': 3.91}\n",
      "{'loss': 2.1689, 'grad_norm': 7.042539119720459, 'learning_rate': 3.0327868852459017e-05, 'epoch': 3.93}\n",
      "{'loss': 2.2116, 'grad_norm': 3.215209722518921, 'learning_rate': 3.0191256830601094e-05, 'epoch': 3.96}\n",
      "{'loss': 2.327, 'grad_norm': 5.8789262771606445, 'learning_rate': 3.005464480874317e-05, 'epoch': 3.99}\n",
      "{'loss': 2.0113, 'grad_norm': 5.094599723815918, 'learning_rate': 2.9918032786885248e-05, 'epoch': 4.02}\n",
      "{'loss': 2.0254, 'grad_norm': 4.238717555999756, 'learning_rate': 2.9781420765027324e-05, 'epoch': 4.04}\n",
      "{'loss': 2.0367, 'grad_norm': 6.922329425811768, 'learning_rate': 2.96448087431694e-05, 'epoch': 4.07}\n",
      "{'loss': 2.0843, 'grad_norm': 4.451197624206543, 'learning_rate': 2.9508196721311478e-05, 'epoch': 4.1}\n",
      "{'loss': 1.8885, 'grad_norm': 6.089724540710449, 'learning_rate': 2.937158469945355e-05, 'epoch': 4.13}\n",
      "{'loss': 1.9483, 'grad_norm': 3.653198480606079, 'learning_rate': 2.9234972677595628e-05, 'epoch': 4.15}\n",
      "{'loss': 2.2, 'grad_norm': 5.196447372436523, 'learning_rate': 2.9098360655737705e-05, 'epoch': 4.18}\n",
      "{'loss': 1.9415, 'grad_norm': 8.179177284240723, 'learning_rate': 2.896174863387978e-05, 'epoch': 4.21}\n",
      "{'loss': 1.9152, 'grad_norm': 4.246234893798828, 'learning_rate': 2.8825136612021858e-05, 'epoch': 4.23}\n",
      "{'loss': 2.029, 'grad_norm': 4.617114067077637, 'learning_rate': 2.8688524590163935e-05, 'epoch': 4.26}\n",
      "{'loss': 1.9673, 'grad_norm': 5.525248050689697, 'learning_rate': 2.8551912568306012e-05, 'epoch': 4.29}\n",
      "{'loss': 1.9685, 'grad_norm': 3.628653049468994, 'learning_rate': 2.841530054644809e-05, 'epoch': 4.32}\n",
      "{'loss': 2.0197, 'grad_norm': 4.607197284698486, 'learning_rate': 2.8278688524590162e-05, 'epoch': 4.34}\n",
      "{'loss': 2.0591, 'grad_norm': 4.132763862609863, 'learning_rate': 2.814207650273224e-05, 'epoch': 4.37}\n",
      "{'loss': 1.9504, 'grad_norm': 4.161442279815674, 'learning_rate': 2.8005464480874316e-05, 'epoch': 4.4}\n",
      "{'loss': 2.0416, 'grad_norm': 3.5908761024475098, 'learning_rate': 2.7868852459016392e-05, 'epoch': 4.43}\n",
      "{'loss': 1.9617, 'grad_norm': 5.337276935577393, 'learning_rate': 2.773224043715847e-05, 'epoch': 4.45}\n",
      "{'loss': 2.0046, 'grad_norm': 3.508807897567749, 'learning_rate': 2.7595628415300546e-05, 'epoch': 4.48}\n",
      "{'loss': 1.923, 'grad_norm': 3.328782081604004, 'learning_rate': 2.7459016393442626e-05, 'epoch': 4.51}\n",
      "{'loss': 1.9179, 'grad_norm': 3.6210367679595947, 'learning_rate': 2.7322404371584703e-05, 'epoch': 4.54}\n",
      "{'loss': 2.0517, 'grad_norm': 4.185276031494141, 'learning_rate': 2.718579234972678e-05, 'epoch': 4.56}\n",
      "{'loss': 2.0919, 'grad_norm': 3.839355945587158, 'learning_rate': 2.7049180327868856e-05, 'epoch': 4.59}\n",
      "{'loss': 1.9502, 'grad_norm': 4.276463985443115, 'learning_rate': 2.6912568306010933e-05, 'epoch': 4.62}\n",
      "{'loss': 1.9384, 'grad_norm': 6.008975505828857, 'learning_rate': 2.677595628415301e-05, 'epoch': 4.64}\n",
      "{'loss': 1.9808, 'grad_norm': 4.105889797210693, 'learning_rate': 2.6639344262295087e-05, 'epoch': 4.67}\n",
      "{'loss': 2.0179, 'grad_norm': 6.409151554107666, 'learning_rate': 2.650273224043716e-05, 'epoch': 4.7}\n",
      "{'loss': 2.0273, 'grad_norm': 5.897883415222168, 'learning_rate': 2.6366120218579237e-05, 'epoch': 4.73}\n",
      "{'loss': 2.0111, 'grad_norm': 4.621446132659912, 'learning_rate': 2.6229508196721314e-05, 'epoch': 4.75}\n",
      "{'loss': 1.9907, 'grad_norm': 5.571615695953369, 'learning_rate': 2.609289617486339e-05, 'epoch': 4.78}\n",
      "{'loss': 1.9581, 'grad_norm': 3.604933500289917, 'learning_rate': 2.5956284153005467e-05, 'epoch': 4.81}\n",
      "{'loss': 1.9429, 'grad_norm': 4.920492172241211, 'learning_rate': 2.5819672131147544e-05, 'epoch': 4.84}\n",
      "{'loss': 2.0322, 'grad_norm': 5.243964195251465, 'learning_rate': 2.568306010928962e-05, 'epoch': 4.86}\n",
      "{'loss': 2.1502, 'grad_norm': 4.3622002601623535, 'learning_rate': 2.5546448087431697e-05, 'epoch': 4.89}\n",
      "{'loss': 2.1036, 'grad_norm': 5.899333953857422, 'learning_rate': 2.540983606557377e-05, 'epoch': 4.92}\n",
      "{'loss': 2.044, 'grad_norm': 6.062138080596924, 'learning_rate': 2.5273224043715848e-05, 'epoch': 4.95}\n",
      "{'loss': 2.0229, 'grad_norm': 2.830965995788574, 'learning_rate': 2.5136612021857924e-05, 'epoch': 4.97}\n",
      "{'loss': 2.0024, 'grad_norm': 7.967601299285889, 'learning_rate': 2.5e-05, 'epoch': 5.0}\n",
      "{'loss': 1.8081, 'grad_norm': 4.129971027374268, 'learning_rate': 2.4863387978142078e-05, 'epoch': 5.03}\n",
      "{'loss': 1.9106, 'grad_norm': 4.308451175689697, 'learning_rate': 2.4726775956284155e-05, 'epoch': 5.05}\n",
      "{'loss': 1.7637, 'grad_norm': 3.378356456756592, 'learning_rate': 2.459016393442623e-05, 'epoch': 5.08}\n",
      "{'loss': 1.8973, 'grad_norm': 6.58413553237915, 'learning_rate': 2.4453551912568305e-05, 'epoch': 5.11}\n",
      "{'loss': 1.9797, 'grad_norm': 7.195268630981445, 'learning_rate': 2.431693989071038e-05, 'epoch': 5.14}\n",
      "{'loss': 1.8755, 'grad_norm': 7.277946949005127, 'learning_rate': 2.418032786885246e-05, 'epoch': 5.16}\n",
      "{'loss': 1.9681, 'grad_norm': 4.331408977508545, 'learning_rate': 2.4043715846994535e-05, 'epoch': 5.19}\n",
      "{'loss': 1.7335, 'grad_norm': 4.003603458404541, 'learning_rate': 2.3907103825136612e-05, 'epoch': 5.22}\n",
      "{'loss': 1.8382, 'grad_norm': 9.34464168548584, 'learning_rate': 2.377049180327869e-05, 'epoch': 5.25}\n",
      "{'loss': 1.8722, 'grad_norm': 3.857295513153076, 'learning_rate': 2.363387978142077e-05, 'epoch': 5.27}\n",
      "{'loss': 1.8773, 'grad_norm': 6.203422546386719, 'learning_rate': 2.3497267759562842e-05, 'epoch': 5.3}\n",
      "{'loss': 1.8667, 'grad_norm': 5.813609600067139, 'learning_rate': 2.336065573770492e-05, 'epoch': 5.33}\n",
      "{'loss': 1.8417, 'grad_norm': 5.357273578643799, 'learning_rate': 2.3224043715846996e-05, 'epoch': 5.36}\n",
      "{'loss': 1.9807, 'grad_norm': 3.6319854259490967, 'learning_rate': 2.3087431693989073e-05, 'epoch': 5.38}\n",
      "{'loss': 1.7574, 'grad_norm': 6.529572010040283, 'learning_rate': 2.295081967213115e-05, 'epoch': 5.41}\n",
      "{'loss': 1.8593, 'grad_norm': 4.807732105255127, 'learning_rate': 2.2814207650273226e-05, 'epoch': 5.44}\n",
      "{'loss': 1.8391, 'grad_norm': 5.444061756134033, 'learning_rate': 2.2677595628415303e-05, 'epoch': 5.46}\n",
      "{'loss': 1.7833, 'grad_norm': 12.050549507141113, 'learning_rate': 2.254098360655738e-05, 'epoch': 5.49}\n",
      "{'loss': 1.8716, 'grad_norm': 8.636277198791504, 'learning_rate': 2.2404371584699453e-05, 'epoch': 5.52}\n",
      "{'loss': 1.86, 'grad_norm': 6.375359535217285, 'learning_rate': 2.226775956284153e-05, 'epoch': 5.55}\n",
      "{'loss': 1.8752, 'grad_norm': 4.333688259124756, 'learning_rate': 2.2131147540983607e-05, 'epoch': 5.57}\n",
      "{'loss': 1.8962, 'grad_norm': 7.863008975982666, 'learning_rate': 2.1994535519125683e-05, 'epoch': 5.6}\n",
      "{'loss': 1.8434, 'grad_norm': 4.057852745056152, 'learning_rate': 2.185792349726776e-05, 'epoch': 5.63}\n",
      "{'loss': 1.9415, 'grad_norm': 5.196486949920654, 'learning_rate': 2.1721311475409837e-05, 'epoch': 5.66}\n",
      "{'loss': 1.8421, 'grad_norm': 5.9459638595581055, 'learning_rate': 2.1584699453551914e-05, 'epoch': 5.68}\n",
      "{'loss': 1.8651, 'grad_norm': 4.987761497497559, 'learning_rate': 2.144808743169399e-05, 'epoch': 5.71}\n",
      "{'loss': 1.955, 'grad_norm': 3.8709933757781982, 'learning_rate': 2.1311475409836064e-05, 'epoch': 5.74}\n",
      "{'loss': 1.7931, 'grad_norm': 5.106514930725098, 'learning_rate': 2.1174863387978144e-05, 'epoch': 5.77}\n",
      "{'loss': 1.9767, 'grad_norm': 6.505019187927246, 'learning_rate': 2.103825136612022e-05, 'epoch': 5.79}\n",
      "{'loss': 1.838, 'grad_norm': 6.175174236297607, 'learning_rate': 2.0901639344262298e-05, 'epoch': 5.82}\n",
      "{'loss': 2.0103, 'grad_norm': 5.382211685180664, 'learning_rate': 2.0765027322404374e-05, 'epoch': 5.85}\n",
      "{'loss': 1.9066, 'grad_norm': 5.200800895690918, 'learning_rate': 2.062841530054645e-05, 'epoch': 5.87}\n",
      "{'loss': 1.8873, 'grad_norm': 4.593117713928223, 'learning_rate': 2.0491803278688525e-05, 'epoch': 5.9}\n",
      "{'loss': 1.8613, 'grad_norm': 3.751713991165161, 'learning_rate': 2.03551912568306e-05, 'epoch': 5.93}\n",
      "{'loss': 1.8423, 'grad_norm': 3.23099684715271, 'learning_rate': 2.0218579234972678e-05, 'epoch': 5.96}\n",
      "{'loss': 1.8212, 'grad_norm': 6.169251441955566, 'learning_rate': 2.0081967213114755e-05, 'epoch': 5.98}\n",
      "{'loss': 1.7685, 'grad_norm': 5.179754257202148, 'learning_rate': 1.994535519125683e-05, 'epoch': 6.01}\n",
      "{'loss': 1.9006, 'grad_norm': 4.691005229949951, 'learning_rate': 1.980874316939891e-05, 'epoch': 6.04}\n",
      "{'loss': 1.8122, 'grad_norm': 4.2495036125183105, 'learning_rate': 1.9672131147540985e-05, 'epoch': 6.07}\n",
      "{'loss': 1.7168, 'grad_norm': 4.206562042236328, 'learning_rate': 1.9535519125683062e-05, 'epoch': 6.09}\n",
      "{'loss': 1.5714, 'grad_norm': 3.6650924682617188, 'learning_rate': 1.9398907103825135e-05, 'epoch': 6.12}\n",
      "{'loss': 1.7805, 'grad_norm': 7.44655704498291, 'learning_rate': 1.9262295081967212e-05, 'epoch': 6.15}\n",
      "{'loss': 1.8489, 'grad_norm': 4.809517860412598, 'learning_rate': 1.912568306010929e-05, 'epoch': 6.17}\n",
      "{'loss': 1.8374, 'grad_norm': 4.631551265716553, 'learning_rate': 1.8989071038251366e-05, 'epoch': 6.2}\n",
      "{'loss': 1.6716, 'grad_norm': 5.820180416107178, 'learning_rate': 1.8852459016393442e-05, 'epoch': 6.23}\n",
      "{'loss': 1.7454, 'grad_norm': 5.265320777893066, 'learning_rate': 1.8715846994535523e-05, 'epoch': 6.26}\n",
      "{'loss': 1.7279, 'grad_norm': 4.890782356262207, 'learning_rate': 1.85792349726776e-05, 'epoch': 6.28}\n",
      "{'loss': 1.6803, 'grad_norm': 7.4828996658325195, 'learning_rate': 1.8442622950819673e-05, 'epoch': 6.31}\n",
      "{'loss': 1.7399, 'grad_norm': 4.517395973205566, 'learning_rate': 1.830601092896175e-05, 'epoch': 6.34}\n",
      "{'loss': 1.8617, 'grad_norm': 6.820906162261963, 'learning_rate': 1.8169398907103826e-05, 'epoch': 6.37}\n",
      "{'loss': 1.7673, 'grad_norm': 7.09811544418335, 'learning_rate': 1.8032786885245903e-05, 'epoch': 6.39}\n",
      "{'loss': 1.8062, 'grad_norm': 6.146137714385986, 'learning_rate': 1.789617486338798e-05, 'epoch': 6.42}\n",
      "{'loss': 1.8382, 'grad_norm': 5.501169204711914, 'learning_rate': 1.7759562841530057e-05, 'epoch': 6.45}\n",
      "{'loss': 1.8629, 'grad_norm': 5.322399139404297, 'learning_rate': 1.7622950819672133e-05, 'epoch': 6.48}\n",
      "{'loss': 1.8105, 'grad_norm': 5.0222859382629395, 'learning_rate': 1.7486338797814207e-05, 'epoch': 6.5}\n",
      "{'loss': 1.6965, 'grad_norm': 4.986813068389893, 'learning_rate': 1.7349726775956284e-05, 'epoch': 6.53}\n",
      "{'loss': 1.7434, 'grad_norm': 4.385021209716797, 'learning_rate': 1.721311475409836e-05, 'epoch': 6.56}\n",
      "{'loss': 1.7675, 'grad_norm': 4.9439778327941895, 'learning_rate': 1.7076502732240437e-05, 'epoch': 6.58}\n",
      "{'loss': 1.7815, 'grad_norm': 4.802975177764893, 'learning_rate': 1.6939890710382514e-05, 'epoch': 6.61}\n",
      "{'loss': 1.6508, 'grad_norm': 3.1244757175445557, 'learning_rate': 1.680327868852459e-05, 'epoch': 6.64}\n",
      "{'loss': 1.64, 'grad_norm': 6.3646111488342285, 'learning_rate': 1.6666666666666667e-05, 'epoch': 6.67}\n",
      "{'loss': 1.7999, 'grad_norm': 6.728321552276611, 'learning_rate': 1.6530054644808744e-05, 'epoch': 6.69}\n",
      "{'loss': 1.8639, 'grad_norm': 4.7951836585998535, 'learning_rate': 1.6393442622950818e-05, 'epoch': 6.72}\n",
      "{'loss': 1.697, 'grad_norm': 3.520423412322998, 'learning_rate': 1.6256830601092894e-05, 'epoch': 6.75}\n",
      "{'loss': 1.8411, 'grad_norm': 4.995837211608887, 'learning_rate': 1.6120218579234975e-05, 'epoch': 6.78}\n",
      "{'loss': 1.7211, 'grad_norm': 4.576601982116699, 'learning_rate': 1.598360655737705e-05, 'epoch': 6.8}\n",
      "{'loss': 1.7692, 'grad_norm': 4.7455925941467285, 'learning_rate': 1.5846994535519128e-05, 'epoch': 6.83}\n",
      "{'loss': 1.8001, 'grad_norm': 7.781632423400879, 'learning_rate': 1.5710382513661205e-05, 'epoch': 6.86}\n",
      "{'loss': 1.8644, 'grad_norm': 5.2151408195495605, 'learning_rate': 1.557377049180328e-05, 'epoch': 6.89}\n",
      "{'loss': 1.7671, 'grad_norm': 4.807450294494629, 'learning_rate': 1.5437158469945355e-05, 'epoch': 6.91}\n",
      "{'loss': 1.7899, 'grad_norm': 8.20547866821289, 'learning_rate': 1.5300546448087432e-05, 'epoch': 6.94}\n",
      "{'loss': 1.7708, 'grad_norm': 5.754690647125244, 'learning_rate': 1.5163934426229509e-05, 'epoch': 6.97}\n",
      "{'loss': 1.7553, 'grad_norm': 5.926288604736328, 'learning_rate': 1.5027322404371585e-05, 'epoch': 6.99}\n",
      "{'loss': 1.6656, 'grad_norm': 4.295401573181152, 'learning_rate': 1.4890710382513662e-05, 'epoch': 7.02}\n",
      "{'loss': 1.7164, 'grad_norm': 7.428957462310791, 'learning_rate': 1.4754098360655739e-05, 'epoch': 7.05}\n",
      "{'loss': 1.6509, 'grad_norm': 6.159915924072266, 'learning_rate': 1.4617486338797814e-05, 'epoch': 7.08}\n",
      "{'loss': 1.7237, 'grad_norm': 3.8546292781829834, 'learning_rate': 1.448087431693989e-05, 'epoch': 7.1}\n",
      "{'loss': 1.7059, 'grad_norm': 5.063492298126221, 'learning_rate': 1.4344262295081968e-05, 'epoch': 7.13}\n",
      "{'loss': 1.6092, 'grad_norm': 5.488382339477539, 'learning_rate': 1.4207650273224044e-05, 'epoch': 7.16}\n",
      "{'loss': 1.7416, 'grad_norm': 5.099580764770508, 'learning_rate': 1.407103825136612e-05, 'epoch': 7.19}\n",
      "{'loss': 1.6469, 'grad_norm': 4.519869327545166, 'learning_rate': 1.3934426229508196e-05, 'epoch': 7.21}\n",
      "{'loss': 1.5964, 'grad_norm': 6.307147026062012, 'learning_rate': 1.3797814207650273e-05, 'epoch': 7.24}\n",
      "{'loss': 1.6371, 'grad_norm': 4.3752593994140625, 'learning_rate': 1.3661202185792351e-05, 'epoch': 7.27}\n",
      "{'loss': 1.7205, 'grad_norm': 3.7936148643493652, 'learning_rate': 1.3524590163934428e-05, 'epoch': 7.3}\n",
      "{'loss': 1.7424, 'grad_norm': 7.951493263244629, 'learning_rate': 1.3387978142076505e-05, 'epoch': 7.32}\n",
      "{'loss': 1.7392, 'grad_norm': 8.456475257873535, 'learning_rate': 1.325136612021858e-05, 'epoch': 7.35}\n",
      "{'loss': 1.7209, 'grad_norm': 6.331320762634277, 'learning_rate': 1.3114754098360657e-05, 'epoch': 7.38}\n",
      "{'loss': 1.6427, 'grad_norm': 3.6745622158050537, 'learning_rate': 1.2978142076502734e-05, 'epoch': 7.4}\n",
      "{'loss': 1.7724, 'grad_norm': 4.7799482345581055, 'learning_rate': 1.284153005464481e-05, 'epoch': 7.43}\n",
      "{'loss': 1.7564, 'grad_norm': 6.188279151916504, 'learning_rate': 1.2704918032786885e-05, 'epoch': 7.46}\n",
      "{'loss': 1.679, 'grad_norm': 6.289374351501465, 'learning_rate': 1.2568306010928962e-05, 'epoch': 7.49}\n",
      "{'loss': 1.5667, 'grad_norm': 4.233798503875732, 'learning_rate': 1.2431693989071039e-05, 'epoch': 7.51}\n",
      "{'loss': 1.6793, 'grad_norm': 6.016992568969727, 'learning_rate': 1.2295081967213116e-05, 'epoch': 7.54}\n",
      "{'loss': 1.6375, 'grad_norm': 5.334875106811523, 'learning_rate': 1.215846994535519e-05, 'epoch': 7.57}\n",
      "{'loss': 1.6373, 'grad_norm': 6.968085289001465, 'learning_rate': 1.2021857923497268e-05, 'epoch': 7.6}\n",
      "{'loss': 1.6434, 'grad_norm': 7.119997501373291, 'learning_rate': 1.1885245901639344e-05, 'epoch': 7.62}\n",
      "{'loss': 1.8415, 'grad_norm': 4.076518535614014, 'learning_rate': 1.1748633879781421e-05, 'epoch': 7.65}\n",
      "{'loss': 1.7655, 'grad_norm': 4.117881774902344, 'learning_rate': 1.1612021857923498e-05, 'epoch': 7.68}\n",
      "{'loss': 1.6836, 'grad_norm': 4.3445305824279785, 'learning_rate': 1.1475409836065575e-05, 'epoch': 7.7}\n",
      "{'loss': 1.6673, 'grad_norm': 6.535335063934326, 'learning_rate': 1.1338797814207651e-05, 'epoch': 7.73}\n",
      "{'loss': 1.4731, 'grad_norm': 9.673873901367188, 'learning_rate': 1.1202185792349727e-05, 'epoch': 7.76}\n",
      "{'loss': 1.7345, 'grad_norm': 4.237600803375244, 'learning_rate': 1.1065573770491803e-05, 'epoch': 7.79}\n",
      "{'loss': 1.6997, 'grad_norm': 3.3572723865509033, 'learning_rate': 1.092896174863388e-05, 'epoch': 7.81}\n",
      "{'loss': 1.7152, 'grad_norm': 3.9852521419525146, 'learning_rate': 1.0792349726775957e-05, 'epoch': 7.84}\n",
      "{'loss': 1.7115, 'grad_norm': 7.569178581237793, 'learning_rate': 1.0655737704918032e-05, 'epoch': 7.87}\n",
      "{'loss': 1.5889, 'grad_norm': 6.787412166595459, 'learning_rate': 1.051912568306011e-05, 'epoch': 7.9}\n",
      "{'loss': 1.5443, 'grad_norm': 5.488717555999756, 'learning_rate': 1.0382513661202187e-05, 'epoch': 7.92}\n",
      "{'loss': 1.6045, 'grad_norm': 5.593503475189209, 'learning_rate': 1.0245901639344262e-05, 'epoch': 7.95}\n",
      "{'loss': 1.695, 'grad_norm': 5.323424339294434, 'learning_rate': 1.0109289617486339e-05, 'epoch': 7.98}\n",
      "{'loss': 1.6471, 'grad_norm': 4.861392498016357, 'learning_rate': 9.972677595628416e-06, 'epoch': 8.01}\n",
      "{'loss': 1.6731, 'grad_norm': 4.57677698135376, 'learning_rate': 9.836065573770493e-06, 'epoch': 8.03}\n",
      "{'loss': 1.5331, 'grad_norm': 9.102288246154785, 'learning_rate': 9.699453551912568e-06, 'epoch': 8.06}\n",
      "{'loss': 1.6127, 'grad_norm': 4.779058456420898, 'learning_rate': 9.562841530054644e-06, 'epoch': 8.09}\n",
      "{'loss': 1.5489, 'grad_norm': 6.657552242279053, 'learning_rate': 9.426229508196721e-06, 'epoch': 8.11}\n",
      "{'loss': 1.6132, 'grad_norm': 3.947725296020508, 'learning_rate': 9.2896174863388e-06, 'epoch': 8.14}\n",
      "{'loss': 1.6224, 'grad_norm': 5.281004905700684, 'learning_rate': 9.153005464480875e-06, 'epoch': 8.17}\n",
      "{'loss': 1.5919, 'grad_norm': 5.822897434234619, 'learning_rate': 9.016393442622952e-06, 'epoch': 8.2}\n",
      "{'loss': 1.5871, 'grad_norm': 5.60066556930542, 'learning_rate': 8.879781420765028e-06, 'epoch': 8.22}\n",
      "{'loss': 1.6414, 'grad_norm': 5.6332902908325195, 'learning_rate': 8.743169398907103e-06, 'epoch': 8.25}\n",
      "{'loss': 1.5415, 'grad_norm': 4.662975788116455, 'learning_rate': 8.60655737704918e-06, 'epoch': 8.28}\n",
      "{'loss': 1.5498, 'grad_norm': 5.094448089599609, 'learning_rate': 8.469945355191257e-06, 'epoch': 8.31}\n",
      "{'loss': 1.6241, 'grad_norm': 4.560925483703613, 'learning_rate': 8.333333333333334e-06, 'epoch': 8.33}\n",
      "{'loss': 1.6118, 'grad_norm': 7.749441623687744, 'learning_rate': 8.196721311475409e-06, 'epoch': 8.36}\n",
      "{'loss': 1.7549, 'grad_norm': 7.038271427154541, 'learning_rate': 8.060109289617487e-06, 'epoch': 8.39}\n",
      "{'loss': 1.5341, 'grad_norm': 5.48264741897583, 'learning_rate': 7.923497267759564e-06, 'epoch': 8.42}\n",
      "{'loss': 1.6976, 'grad_norm': 5.704436302185059, 'learning_rate': 7.78688524590164e-06, 'epoch': 8.44}\n",
      "{'loss': 1.5515, 'grad_norm': 5.189659595489502, 'learning_rate': 7.650273224043716e-06, 'epoch': 8.47}\n",
      "{'loss': 1.5615, 'grad_norm': 4.604428291320801, 'learning_rate': 7.513661202185793e-06, 'epoch': 8.5}\n",
      "{'loss': 1.5842, 'grad_norm': 4.227879047393799, 'learning_rate': 7.3770491803278695e-06, 'epoch': 8.52}\n",
      "{'loss': 1.6348, 'grad_norm': 7.026705741882324, 'learning_rate': 7.240437158469945e-06, 'epoch': 8.55}\n",
      "{'loss': 1.7196, 'grad_norm': 9.920846939086914, 'learning_rate': 7.103825136612022e-06, 'epoch': 8.58}\n",
      "{'loss': 1.655, 'grad_norm': 4.098590850830078, 'learning_rate': 6.967213114754098e-06, 'epoch': 8.61}\n",
      "{'loss': 1.7097, 'grad_norm': 6.120113849639893, 'learning_rate': 6.830601092896176e-06, 'epoch': 8.63}\n",
      "{'loss': 1.5456, 'grad_norm': 5.7390055656433105, 'learning_rate': 6.6939890710382525e-06, 'epoch': 8.66}\n",
      "{'loss': 1.7238, 'grad_norm': 6.068156719207764, 'learning_rate': 6.557377049180328e-06, 'epoch': 8.69}\n",
      "{'loss': 1.6978, 'grad_norm': 7.17195463180542, 'learning_rate': 6.420765027322405e-06, 'epoch': 8.72}\n",
      "{'loss': 1.6059, 'grad_norm': 5.625977516174316, 'learning_rate': 6.284153005464481e-06, 'epoch': 8.74}\n",
      "{'loss': 1.6417, 'grad_norm': 3.2739384174346924, 'learning_rate': 6.147540983606558e-06, 'epoch': 8.77}\n",
      "{'loss': 1.5926, 'grad_norm': 6.0631537437438965, 'learning_rate': 6.010928961748634e-06, 'epoch': 8.8}\n",
      "{'loss': 1.6345, 'grad_norm': 5.564788341522217, 'learning_rate': 5.874316939890711e-06, 'epoch': 8.83}\n",
      "{'loss': 1.5016, 'grad_norm': 5.87352991104126, 'learning_rate': 5.737704918032787e-06, 'epoch': 8.85}\n",
      "{'loss': 1.6022, 'grad_norm': 6.192246913909912, 'learning_rate': 5.601092896174863e-06, 'epoch': 8.88}\n",
      "{'loss': 1.6245, 'grad_norm': 7.10530948638916, 'learning_rate': 5.46448087431694e-06, 'epoch': 8.91}\n",
      "{'loss': 1.5285, 'grad_norm': 5.666266918182373, 'learning_rate': 5.327868852459016e-06, 'epoch': 8.93}\n",
      "{'loss': 1.557, 'grad_norm': 5.309338092803955, 'learning_rate': 5.191256830601094e-06, 'epoch': 8.96}\n",
      "{'loss': 1.6019, 'grad_norm': 5.05779504776001, 'learning_rate': 5.0546448087431695e-06, 'epoch': 8.99}\n",
      "{'loss': 1.5714, 'grad_norm': 6.320865154266357, 'learning_rate': 4.918032786885246e-06, 'epoch': 9.02}\n",
      "{'loss': 1.6404, 'grad_norm': 5.577891826629639, 'learning_rate': 4.781420765027322e-06, 'epoch': 9.04}\n",
      "{'loss': 1.5873, 'grad_norm': 6.498589038848877, 'learning_rate': 4.6448087431694e-06, 'epoch': 9.07}\n",
      "{'loss': 1.5224, 'grad_norm': 5.085691452026367, 'learning_rate': 4.508196721311476e-06, 'epoch': 9.1}\n",
      "{'loss': 1.534, 'grad_norm': 6.598575592041016, 'learning_rate': 4.371584699453552e-06, 'epoch': 9.13}\n",
      "{'loss': 1.5162, 'grad_norm': 3.938706636428833, 'learning_rate': 4.2349726775956285e-06, 'epoch': 9.15}\n",
      "{'loss': 1.6032, 'grad_norm': 5.250040054321289, 'learning_rate': 4.098360655737704e-06, 'epoch': 9.18}\n",
      "{'loss': 1.658, 'grad_norm': 6.520531177520752, 'learning_rate': 3.961748633879782e-06, 'epoch': 9.21}\n",
      "{'loss': 1.6121, 'grad_norm': 7.492585182189941, 'learning_rate': 3.825136612021858e-06, 'epoch': 9.23}\n",
      "{'loss': 1.5357, 'grad_norm': 5.776654243469238, 'learning_rate': 3.6885245901639347e-06, 'epoch': 9.26}\n",
      "{'loss': 1.5548, 'grad_norm': 5.842360973358154, 'learning_rate': 3.551912568306011e-06, 'epoch': 9.29}\n",
      "{'loss': 1.6151, 'grad_norm': 5.313436985015869, 'learning_rate': 3.415300546448088e-06, 'epoch': 9.32}\n",
      "{'loss': 1.4329, 'grad_norm': 6.451517105102539, 'learning_rate': 3.278688524590164e-06, 'epoch': 9.34}\n",
      "{'loss': 1.6389, 'grad_norm': 12.466889381408691, 'learning_rate': 3.1420765027322406e-06, 'epoch': 9.37}\n",
      "{'loss': 1.517, 'grad_norm': 4.201379776000977, 'learning_rate': 3.005464480874317e-06, 'epoch': 9.4}\n",
      "{'loss': 1.6852, 'grad_norm': 5.777804374694824, 'learning_rate': 2.8688524590163937e-06, 'epoch': 9.43}\n",
      "{'loss': 1.5814, 'grad_norm': 5.198677062988281, 'learning_rate': 2.73224043715847e-06, 'epoch': 9.45}\n",
      "{'loss': 1.6475, 'grad_norm': 5.668834686279297, 'learning_rate': 2.595628415300547e-06, 'epoch': 9.48}\n",
      "{'loss': 1.6076, 'grad_norm': 5.6962432861328125, 'learning_rate': 2.459016393442623e-06, 'epoch': 9.51}\n",
      "{'loss': 1.4722, 'grad_norm': 2.483405351638794, 'learning_rate': 2.3224043715847e-06, 'epoch': 9.54}\n",
      "{'loss': 1.5679, 'grad_norm': 4.641810417175293, 'learning_rate': 2.185792349726776e-06, 'epoch': 9.56}\n",
      "{'loss': 1.5465, 'grad_norm': 4.968545436859131, 'learning_rate': 2.049180327868852e-06, 'epoch': 9.59}\n",
      "{'loss': 1.6221, 'grad_norm': 7.266144275665283, 'learning_rate': 1.912568306010929e-06, 'epoch': 9.62}\n",
      "{'loss': 1.6577, 'grad_norm': 6.912889003753662, 'learning_rate': 1.7759562841530055e-06, 'epoch': 9.64}\n",
      "{'loss': 1.4484, 'grad_norm': 5.16395378112793, 'learning_rate': 1.639344262295082e-06, 'epoch': 9.67}\n",
      "{'loss': 1.5396, 'grad_norm': 4.282991409301758, 'learning_rate': 1.5027322404371585e-06, 'epoch': 9.7}\n",
      "{'loss': 1.4672, 'grad_norm': 6.187832355499268, 'learning_rate': 1.366120218579235e-06, 'epoch': 9.73}\n",
      "{'loss': 1.6056, 'grad_norm': 6.412017822265625, 'learning_rate': 1.2295081967213116e-06, 'epoch': 9.75}\n",
      "{'loss': 1.5676, 'grad_norm': 5.107054710388184, 'learning_rate': 1.092896174863388e-06, 'epoch': 9.78}\n",
      "{'loss': 1.6048, 'grad_norm': 5.071347713470459, 'learning_rate': 9.562841530054645e-07, 'epoch': 9.81}\n",
      "{'loss': 1.5736, 'grad_norm': 5.119495868682861, 'learning_rate': 8.19672131147541e-07, 'epoch': 9.84}\n",
      "{'loss': 1.6324, 'grad_norm': 5.714518070220947, 'learning_rate': 6.830601092896175e-07, 'epoch': 9.86}\n",
      "{'loss': 1.5921, 'grad_norm': 6.188709259033203, 'learning_rate': 5.46448087431694e-07, 'epoch': 9.89}\n",
      "{'loss': 1.5138, 'grad_norm': 4.448397159576416, 'learning_rate': 4.098360655737705e-07, 'epoch': 9.92}\n",
      "{'loss': 1.5719, 'grad_norm': 9.478008270263672, 'learning_rate': 2.73224043715847e-07, 'epoch': 9.95}\n",
      "{'loss': 1.5081, 'grad_norm': 3.8700978755950928, 'learning_rate': 1.366120218579235e-07, 'epoch': 9.97}\n",
      "{'loss': 1.6201, 'grad_norm': 6.454488754272461, 'learning_rate': 0.0, 'epoch': 10.0}\n",
      "{'train_runtime': 5607.2911, 'train_samples_per_second': 13.053, 'train_steps_per_second': 6.527, 'train_loss': 2.0524277508845095, 'epoch': 10.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=36600, training_loss=2.0524277508845095, metrics={'train_runtime': 5607.2911, 'train_samples_per_second': 13.053, 'train_steps_per_second': 6.527, 'total_flos': 9561254682240000.0, 'train_loss': 2.0524277508845095, 'epoch': 10.0})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
>>>>>>> 45d5d7512a259e119af2d0a0d1b085bad01865bc
    }
   ],
   "source": [
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=10,\n",
    "    per_device_train_batch_size=2,\n",
    "    save_steps=10_000,\n",
    "    save_total_limit=5,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=100,\n",
    "    report_to=\"comet_ml\",  # Ensure training logs are sent to Comet\n",
    ")\n",
    "\n",
    "# Instantiate Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=tokenized_train_dataset,\n",
    "    #eval_dataset=tokenized_test_dataset,\n",
    "    compute_metrics=None,  # Add compute_metrics function if needed\n",
    ")\n",
    "\n",
    "# Fine-tune the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./fine_tuned_rap_model\\\\tokenizer_config.json',\n",
       " './fine_tuned_rap_model\\\\special_tokens_map.json',\n",
       " './fine_tuned_rap_model\\\\vocab.json',\n",
       " './fine_tuned_rap_model\\\\merges.txt',\n",
       " './fine_tuned_rap_model\\\\added_tokens.json',\n",
       " './fine_tuned_rap_model\\\\tokenizer.json')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the fine-tuned model\n",
    "model.save_pretrained('./fine_tuned_rap_model')\n",
    "tokenizer.save_pretrained('./fine_tuned_rap_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics = trainer.evaluate(eval_dataset=tokenized_test_dataset)\n",
    "# experiment.log_metrics(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml Experiment Summary\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     name                  : vocational_jabuticaba_8795\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : https://www.comet.com/artaasd95/rap-lyrics-generator-llm/691a08178eb6451eb726ef00fac1e644\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Metrics [count] (min, max):\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     loss [3660]                    : (0.11254338920116425, 4.750914573669434)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/epoch [367]              : (0.0273224043715847, 10.0)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/grad_norm [366]          : (2.4674980640411377, 15.807796478271484)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/learning_rate [366]      : (0.0, 4.986338797814208e-05)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/loss [366]               : (1.4329, 3.2603)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/total_flos               : 9561254682240000.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/train_loss               : 2.0524277508845095\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/train_runtime            : 5607.2911\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/train_samples_per_second : 13.053\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/train_steps_per_second   : 6.527\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Others:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hasNestedParams : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Parameters:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|accelerator_config|dispatch_batches               : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|accelerator_config|even_batches                   : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|accelerator_config|gradient_accumulation_kwargs   : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|accelerator_config|non_blocking                   : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|accelerator_config|split_batches                  : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|accelerator_config|use_seedable_sampler           : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|adafactor                                         : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|adam_beta1                                        : 0.9\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|adam_beta2                                        : 0.999\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|adam_epsilon                                      : 1e-08\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|auto_find_batch_size                              : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|batch_eval_metrics                                : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|bf16                                              : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|bf16_full_eval                                    : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|data_seed                                         : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|dataloader_drop_last                              : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|dataloader_num_workers                            : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|dataloader_persistent_workers                     : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|dataloader_pin_memory                             : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|dataloader_prefetch_factor                        : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|ddp_backend                                       : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|ddp_broadcast_buffers                             : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|ddp_bucket_cap_mb                                 : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|ddp_find_unused_parameters                        : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|ddp_timeout                                       : 1800\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|debug                                             : []\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|deepspeed                                         : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|disable_tqdm                                      : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|dispatch_batches                                  : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|do_eval                                           : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|do_predict                                        : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|do_train                                          : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|eval_accumulation_steps                           : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|eval_delay                                        : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|eval_do_concat_batches                            : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|eval_on_start                                     : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|eval_steps                                        : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|eval_strategy                                     : no\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|eval_use_gather_object                            : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|evaluation_strategy                               : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|fp16                                              : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|fp16_backend                                      : auto\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|fp16_full_eval                                    : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|fp16_opt_level                                    : O1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|fsdp                                              : []\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|fsdp_config|min_num_params                        : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|fsdp_config|xla                                   : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|fsdp_config|xla_fsdp_grad_ckpt                    : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|fsdp_config|xla_fsdp_v2                           : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|fsdp_min_num_params                               : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|fsdp_transformer_layer_cls_to_wrap                : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|full_determinism                                  : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|gradient_accumulation_steps                       : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|gradient_checkpointing                            : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|gradient_checkpointing_kwargs                     : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|greater_is_better                                 : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|group_by_length                                   : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|half_precision_backend                            : auto\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|hub_always_push                                   : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|hub_model_id                                      : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|hub_private_repo                                  : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|hub_strategy                                      : every_save\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|hub_token                                         : <HUB_TOKEN>\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|ignore_data_skip                                  : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|include_for_metrics                               : []\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|include_inputs_for_metrics                        : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|include_num_input_tokens_seen                     : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|include_tokens_per_second                         : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|jit_mode_eval                                     : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|label_names                                       : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|label_smoothing_factor                            : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|learning_rate                                     : 5e-05\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|length_column_name                                : length\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|load_best_model_at_end                            : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|local_rank                                        : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|log_level                                         : passive\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|log_level_replica                                 : warning\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|log_on_each_node                                  : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|logging_dir                                       : ./logs\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|logging_first_step                                : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|logging_nan_inf_filter                            : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|logging_steps                                     : 100\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|logging_strategy                                  : steps\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|lr_scheduler_kwargs                               : {}\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|lr_scheduler_type                                 : linear\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|max_grad_norm                                     : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|max_steps                                         : -1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|metric_for_best_model                             : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|mp_parameters                                     : \n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|neftune_noise_alpha                               : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|no_cuda                                           : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|num_train_epochs                                  : 10\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|optim                                             : adamw_torch\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|optim_args                                        : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|optim_target_modules                              : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|output_dir                                        : ./results\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|overwrite_output_dir                              : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|past_index                                        : -1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|per_device_eval_batch_size                        : 8\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|per_device_train_batch_size                       : 2\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|per_gpu_eval_batch_size                           : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|per_gpu_train_batch_size                          : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|prediction_loss_only                              : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|push_to_hub                                       : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|push_to_hub_model_id                              : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|push_to_hub_organization                          : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|push_to_hub_token                                 : <PUSH_TO_HUB_TOKEN>\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|ray_scope                                         : last\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|remove_unused_columns                             : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|report_to                                         : ['comet_ml']\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|restore_callback_states_from_checkpoint           : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|resume_from_checkpoint                            : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|run_name                                          : ./results\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|save_on_each_node                                 : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|save_only_model                                   : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|save_safetensors                                  : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|save_steps                                        : 10000\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|save_strategy                                     : steps\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|save_total_limit                                  : 5\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|seed                                              : 42\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|skip_memory_metrics                               : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|split_batches                                     : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|tf32                                              : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|torch_compile                                     : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|torch_compile_backend                             : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|torch_compile_mode                                : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|torch_empty_cache_steps                           : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|torchdynamo                                       : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|tpu_metrics_debug                                 : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|tpu_num_cores                                     : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|use_cpu                                           : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|use_ipex                                          : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|use_legacy_prediction_loop                        : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|use_liger_kernel                                  : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|use_mps_device                                    : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|warmup_ratio                                      : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|warmup_steps                                      : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|weight_decay                                      : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|_attn_implementation_autoset                    : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|_name_or_path                                   : gpt2\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|activation_function                             : gelu_new\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|add_cross_attention                             : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|architectures                                   : ['GPT2LMHeadModel']\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|attn_pdrop                                      : 0.1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|bad_words_ids                                   : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|begin_suppress_tokens                           : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|bos_token_id                                    : 50256\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|chunk_size_feed_forward                         : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|cross_attention_hidden_size                     : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|decoder_start_token_id                          : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|diversity_penalty                               : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|do_sample                                       : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|early_stopping                                  : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|embd_pdrop                                      : 0.1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|encoder_no_repeat_ngram_size                    : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|eos_token_id                                    : 50256\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|exponential_decay_length_penalty                : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|finetuning_task                                 : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|forced_bos_token_id                             : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|forced_eos_token_id                             : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|id2label|0                                      : LABEL_0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|id2label|1                                      : LABEL_1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|initializer_range                               : 0.02\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|is_decoder                                      : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|is_encoder_decoder                              : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|label2id|LABEL_0                                : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|label2id|LABEL_1                                : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|layer_norm_epsilon                              : 1e-05\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|length_penalty                                  : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|max_length                                      : 20\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|min_length                                      : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|model_type                                      : gpt2\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|n_ctx                                           : 1024\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|n_embd                                          : 768\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|n_head                                          : 12\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|n_inner                                         : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|n_layer                                         : 12\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|n_positions                                     : 1024\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|no_repeat_ngram_size                            : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|num_beam_groups                                 : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|num_beams                                       : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|num_return_sequences                            : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|output_attentions                               : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|output_hidden_states                            : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|output_scores                                   : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|pad_token_id                                    : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|prefix                                          : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|problem_type                                    : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|pruned_heads                                    : {}\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|remove_invalid_values                           : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|reorder_and_upcast_attn                         : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|repetition_penalty                              : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|resid_pdrop                                     : 0.1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|return_dict                                     : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|return_dict_in_generate                         : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|scale_attn_by_inverse_layer_idx                 : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|scale_attn_weights                              : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|sep_token_id                                    : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|summary_activation                              : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|summary_first_dropout                           : 0.1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|summary_proj_to_labels                          : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|summary_type                                    : cls_index\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|summary_use_proj                                : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|suppress_tokens                                 : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|task_specific_params|text-generation|do_sample  : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|task_specific_params|text-generation|max_length : 50\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|temperature                                     : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|tf_legacy_loss                                  : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|tie_encoder_decoder                             : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|tie_word_embeddings                             : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|tokenizer_class                                 : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|top_k                                           : 50\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|top_p                                           : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|torch_dtype                                     : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|torchscript                                     : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|transformers_version                            : 4.46.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|typical_p                                       : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|use_bfloat16                                    : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|use_cache                                       : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|vocab_size                                      : 50258\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     num_train_epochs                                       : 10\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     per_device_train_batch_size                            : 2\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Uploads:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     environment details : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     filename            : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     git metadata        : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     installed packages  : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model graph         : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     notebook            : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source_code         : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m \n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Please wait for metadata to finish uploading (timeout is 3600 seconds)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Uploading 254 metrics, params and output messages\n"
     ]
    }
   ],
   "source": [
    "experiment.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmgpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
