{
    "cells": [
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "# Style-Based Rap Lyrics Generation\n",
       "\n",
       "This notebook implements style-based rap lyrics generation that can mimic specific rappers' styles based on reference lyrics."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "import torch\n",
       "import torch.nn as nn\n",
       "import torch.nn.functional as F\n",
       "from torch.utils.data import Dataset, DataLoader\n",
       "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments\n",
       "from datasets import load_dataset, Dataset\n",
       "import numpy as np\n",
       "from tqdm import tqdm\n",
       "import os\n",
       "import json"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "class RapStyleDataset(Dataset):\n",
       "    def __init__(self, dataset_path, tokenizer, max_length=512):\n",
       "        self.tokenizer = tokenizer\n",
       "        self.max_length = max_length\n",
       "        \n",
       "        # Load the dataset\n",
       "        with open(dataset_path, 'r') as f:\n",
       "            self.data = json.load(f)\n",
       "        \n",
       "    def __len__(self):\n",
       "        return len(self.data)\n",
       "    \n",
       "    def __getitem__(self, idx):\n",
       "        item = self.data[idx]\n",
       "        \n",
       "        # Format the input with style reference\n",
       "        style_reference = item['style_reference']\n",
       "        prompt = item['prompt']\n",
       "        \n",
       "        # Create the full input text\n",
       "        input_text = f\"Style Reference: {style_reference}\\nPrompt: {prompt}\"\n",
       "        \n",
       "        # Tokenize\n",
       "        tokens = self.tokenizer(\n",
       "            input_text,\n",
       "            truncation=True,\n",
       "            max_length=self.max_length,\n",
       "            padding='max_length',\n",
       "            return_tensors='pt'\n",
       "        )\n",
       "        \n",
       "        return {\n",
       "            'input_ids': tokens['input_ids'].squeeze(),\n",
       "            'attention_mask': tokens['attention_mask'].squeeze(),\n",
       "            'style_reference': style_reference,\n",
       "            'prompt': prompt\n",
       "        }"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "class StyleBasedGenerator:\n",
       "    def __init__(self, model_path, tokenizer_path):\n",
       "        self.tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)\n",
       "        self.model = AutoModelForCausalLM.from_pretrained(model_path)\n",
       "        \n",
       "    def generate_lyrics(self, style_reference, prompt, max_length=200, num_return_sequences=1):\n",
       "        # Format the input\n",
       "        input_text = f\"Style Reference: {style_reference}\\nPrompt: {prompt}\"\n",
       "        \n",
       "        # Tokenize\n",
       "        inputs = self.tokenizer(input_text, return_tensors=\"pt\")\n",
       "        \n",
       "        # Generate\n",
       "        outputs = self.model.generate(\n",
       "            inputs['input_ids'],\n",
       "            max_length=max_length,\n",
       "            num_return_sequences=num_return_sequences,\n",
       "            temperature=0.7,\n",
       "            top_p=0.9,\n",
       "            do_sample=True,\n",
       "            pad_token_id=self.tokenizer.eos_token_id\n",
       "        )\n",
       "        \n",
       "        # Decode and return\n",
       "        generated_texts = []\n",
       "        for output in outputs:\n",
       "            text = self.tokenizer.decode(output, skip_special_tokens=True)\n",
       "            # Extract only the generated part (after the prompt)\n",
       "            generated_part = text.split(prompt)[-1].strip()\n",
       "            generated_texts.append(generated_part)\n",
       "        \n",
       "        return generated_texts"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "def prepare_style_dataset(lyrics_data, output_path):\n",
       "    \"\"\"Prepare a dataset for style-based training.\n",
       "    \n",
       "    Args:\n",
       "        lyrics_data: List of dictionaries containing 'artist', 'lyrics', and 'style_reference'\n",
       "        output_path: Path to save the processed dataset\n",
       "    \"\"\"\n",
       "    processed_data = []\n",
       "    \n",
       "    for item in lyrics_data:\n",
       "        # Extract first few lines as prompt\n",
       "        lines = item['lyrics'].split('\\n')\n",
       "        prompt = '\\n'.join(lines[:2])\n",
       "        \n",
       "        processed_item = {\n",
       "            'style_reference': item['style_reference'],\n",
       "            'prompt': prompt,\n",
       "            'artist': item['artist']\n",
       "        }\n",
       "        processed_data.append(processed_item)\n",
       "    \n",
       "    # Save to JSON\n",
       "    with open(output_path, 'w') as f:\n",
       "        json.dump(processed_data, f, indent=2)"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# Example usage of the style-based generator\n",
       "def generate_style_based_rap(style_reference, prompt):\n",
       "    # Initialize the generator\n",
       "    generator = StyleBasedGenerator(\n",
       "        model_path='checkpoints/dpo_trained_model',\n",
       "        tokenizer_path='checkpoints/dpo_trained_model'\n",
       "    )\n",
       "    \n",
       "    # Generate lyrics\n",
       "    generated_lyrics = generator.generate_lyrics(\n",
       "        style_reference=style_reference,\n",
       "        prompt=prompt,\n",
       "        max_length=200,\n",
       "        num_return_sequences=3\n",
       "    )\n",
       "    \n",
       "    return generated_lyrics"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# Example usage\n",
       "style_reference = \"Eminem's style: Fast-paced, complex wordplay, aggressive tone, and dark humor\"\n",
       "prompt = \"Look, I was gonna go easy on you not to hurt your feelings\\nBut I'm only going to get this one chance\"\n",
       "\n",
       "generated_lyrics = generate_style_based_rap(style_reference, prompt)\n",
       "print(\"Generated Lyrics:\")\n",
       "for i, lyrics in enumerate(generated_lyrics, 1):\n",
       "    print(f\"\\nVersion {i}:\")\n",
       "    print(lyrics)"
      ]
     }
    ],
    "metadata": {
     "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
     },
     "language_info": {
      "codemirror_mode": {
       "name": "ipython",
       "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
     }
    },
    "nbformat": 4,
    "nbformat_minor": 2
   } 