{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import comet_ml\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, DataCollatorForLanguageModeling\n",
    "import datasets\n",
    "from transformers import logging, Trainer, TrainingArguments, DataCollatorForLanguageModeling\n",
    "from itertools import combinations\n",
    "import numpy as np\n",
    "import api_keys\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml Experiment Summary\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     name                  : poised_hamburger_607\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : https://www.comet.com/artaasd95/rap-lyrics-generator-llm/13404e1c0d7241b4baf92d2c6d045d77\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Parameters:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     num_train_epochs            : 3\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     per_device_train_batch_size : 2\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Uploads:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     environment details      : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     filename                 : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     git metadata             : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     git-patch (uncompressed) : 1 (519 bytes)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     installed packages       : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     notebook                 : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source_code              : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m \n",
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/artaasd95/rap-lyrics-generator-llm/cc4cab51aa9944e1a4e6f8dcd45a3d30\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m Unknown error exporting current conda environment\n",
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m Unknown error retrieving Conda package as an explicit file\n",
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m Unknown error retrieving Conda information\n"
     ]
    }
   ],
   "source": [
    "experiment = comet_ml.Experiment(api_key=api_keys.comet, project_name='rap-lyrics-generator-llm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.log_parameters({\n",
    "    \"num_train_epochs\": 5,\n",
    "    \"per_device_train_batch_size\": 2,\n",
    "    # Add any other relevant hyperparameters here\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rap_lyrics_train_dataset = datasets.load_dataset(\"nateraw/rap-lyrics-v2\", split='train')\n",
    "#rap_lyrics_train_dataset = rap_lyrics_train_dataset[:int(len(rap_lyrics_train_dataset)*0.7)]\n",
    "#rap_lyrics_test_dataset = datasets.load_dataset(\"nateraw/rap-lyrics-v2\", split='train')[int(len(rap_lyrics_train_dataset)*0.7):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Embedding(50258, 768)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"gpt2\"  # You could use a larger model like gpt2-medium for better performance\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "model.resize_token_embeddings(len(tokenizer))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4a9fc8cda5a491ebff202f6c6b93797",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7319 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['text'], truncation=True, padding=True, max_length=8092)\n",
    "\n",
    "# Tokenize dataset\n",
    "tokenized_train_dataset = rap_lyrics_train_dataset.map(tokenize_function, batched=True, remove_columns=[\"text\"])\n",
    "\n",
    "# Create a data collator for dynamic batching\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
    "\n",
    "# tokenized_test_dataset = rap_lyrics_train_dataset.map(tokenize_function, batched=True, remove_columns=[\"text\"])\n",
    "# data_collator_test = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m An experiment with the same configuration options is already running and will be reused.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db454c07c74e479dbf1275e61978f9dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.2603, 'grad_norm': 15.812793731689453, 'learning_rate': 4.9726775956284156e-05, 'epoch': 0.03}\n",
      "{'loss': 2.988, 'grad_norm': 11.727437019348145, 'learning_rate': 4.945355191256831e-05, 'epoch': 0.05}\n",
      "{'loss': 3.1803, 'grad_norm': 7.573428630828857, 'learning_rate': 4.918032786885246e-05, 'epoch': 0.08}\n",
      "{'loss': 3.1779, 'grad_norm': 8.897269248962402, 'learning_rate': 4.890710382513661e-05, 'epoch': 0.11}\n",
      "{'loss': 3.1598, 'grad_norm': 10.217747688293457, 'learning_rate': 4.863387978142076e-05, 'epoch': 0.14}\n",
      "{'loss': 3.0267, 'grad_norm': 5.547766208648682, 'learning_rate': 4.836065573770492e-05, 'epoch': 0.16}\n",
      "{'loss': 2.9938, 'grad_norm': 4.865967273712158, 'learning_rate': 4.808743169398907e-05, 'epoch': 0.19}\n",
      "{'loss': 3.1659, 'grad_norm': 7.977914333343506, 'learning_rate': 4.7814207650273224e-05, 'epoch': 0.22}\n",
      "{'loss': 2.9804, 'grad_norm': 5.74665641784668, 'learning_rate': 4.754098360655738e-05, 'epoch': 0.25}\n",
      "{'loss': 2.999, 'grad_norm': 5.771641254425049, 'learning_rate': 4.726775956284154e-05, 'epoch': 0.27}\n",
      "{'loss': 3.0674, 'grad_norm': 4.371352672576904, 'learning_rate': 4.6994535519125685e-05, 'epoch': 0.3}\n",
      "{'loss': 2.9458, 'grad_norm': 3.9278130531311035, 'learning_rate': 4.672131147540984e-05, 'epoch': 0.33}\n",
      "{'loss': 3.0398, 'grad_norm': 3.241208076477051, 'learning_rate': 4.644808743169399e-05, 'epoch': 0.36}\n",
      "{'loss': 2.9403, 'grad_norm': 3.97456431388855, 'learning_rate': 4.6174863387978145e-05, 'epoch': 0.38}\n",
      "{'loss': 2.8589, 'grad_norm': 4.888021945953369, 'learning_rate': 4.59016393442623e-05, 'epoch': 0.41}\n",
      "{'loss': 2.9174, 'grad_norm': 3.3992953300476074, 'learning_rate': 4.562841530054645e-05, 'epoch': 0.44}\n",
      "{'loss': 2.8707, 'grad_norm': 3.5179052352905273, 'learning_rate': 4.5355191256830606e-05, 'epoch': 0.46}\n",
      "{'loss': 2.8151, 'grad_norm': 4.576262474060059, 'learning_rate': 4.508196721311476e-05, 'epoch': 0.49}\n",
      "{'loss': 2.9591, 'grad_norm': 2.738469362258911, 'learning_rate': 4.4808743169398906e-05, 'epoch': 0.52}\n",
      "{'loss': 2.8484, 'grad_norm': 3.391010284423828, 'learning_rate': 4.453551912568306e-05, 'epoch': 0.55}\n",
      "{'loss': 2.8388, 'grad_norm': 4.801701068878174, 'learning_rate': 4.426229508196721e-05, 'epoch': 0.57}\n",
      "{'loss': 2.7942, 'grad_norm': 3.3581368923187256, 'learning_rate': 4.398907103825137e-05, 'epoch': 0.6}\n",
      "{'loss': 2.8924, 'grad_norm': 6.377297878265381, 'learning_rate': 4.371584699453552e-05, 'epoch': 0.63}\n",
      "{'loss': 2.9095, 'grad_norm': 3.268136501312256, 'learning_rate': 4.3442622950819674e-05, 'epoch': 0.66}\n",
      "{'loss': 2.9286, 'grad_norm': 3.862215280532837, 'learning_rate': 4.316939890710383e-05, 'epoch': 0.68}\n",
      "{'loss': 2.8672, 'grad_norm': 3.7023074626922607, 'learning_rate': 4.289617486338798e-05, 'epoch': 0.71}\n",
      "{'loss': 2.8928, 'grad_norm': 4.204445838928223, 'learning_rate': 4.262295081967213e-05, 'epoch': 0.74}\n",
      "{'loss': 2.7833, 'grad_norm': 2.7357280254364014, 'learning_rate': 4.234972677595629e-05, 'epoch': 0.77}\n",
      "{'loss': 2.9102, 'grad_norm': 3.9565963745117188, 'learning_rate': 4.207650273224044e-05, 'epoch': 0.79}\n",
      "{'loss': 2.9403, 'grad_norm': 3.9683308601379395, 'learning_rate': 4.1803278688524595e-05, 'epoch': 0.82}\n",
      "{'loss': 2.8716, 'grad_norm': 3.5148849487304688, 'learning_rate': 4.153005464480875e-05, 'epoch': 0.85}\n",
      "{'loss': 2.9756, 'grad_norm': 3.942708730697632, 'learning_rate': 4.12568306010929e-05, 'epoch': 0.87}\n",
      "{'loss': 2.719, 'grad_norm': 3.7946524620056152, 'learning_rate': 4.098360655737705e-05, 'epoch': 0.9}\n",
      "{'loss': 2.9345, 'grad_norm': 4.781132698059082, 'learning_rate': 4.07103825136612e-05, 'epoch': 0.93}\n",
      "{'loss': 2.7401, 'grad_norm': 6.971726417541504, 'learning_rate': 4.0437158469945356e-05, 'epoch': 0.96}\n",
      "{'loss': 2.8283, 'grad_norm': 3.3701374530792236, 'learning_rate': 4.016393442622951e-05, 'epoch': 0.98}\n",
      "{'loss': 2.708, 'grad_norm': 3.245607376098633, 'learning_rate': 3.989071038251366e-05, 'epoch': 1.01}\n",
      "{'loss': 2.5252, 'grad_norm': 3.7805283069610596, 'learning_rate': 3.961748633879782e-05, 'epoch': 1.04}\n",
      "{'loss': 2.6072, 'grad_norm': 3.5773000717163086, 'learning_rate': 3.934426229508197e-05, 'epoch': 1.07}\n",
      "{'loss': 2.6744, 'grad_norm': 3.618872880935669, 'learning_rate': 3.9071038251366124e-05, 'epoch': 1.09}\n",
      "{'loss': 2.6622, 'grad_norm': 2.9851412773132324, 'learning_rate': 3.879781420765027e-05, 'epoch': 1.12}\n",
      "{'loss': 2.602, 'grad_norm': 7.510007858276367, 'learning_rate': 3.8524590163934424e-05, 'epoch': 1.15}\n",
      "{'loss': 2.658, 'grad_norm': 3.597088098526001, 'learning_rate': 3.825136612021858e-05, 'epoch': 1.17}\n",
      "{'loss': 2.6251, 'grad_norm': 6.608826160430908, 'learning_rate': 3.797814207650273e-05, 'epoch': 1.2}\n",
      "{'loss': 2.6475, 'grad_norm': 4.614305019378662, 'learning_rate': 3.7704918032786885e-05, 'epoch': 1.23}\n",
      "{'loss': 2.5071, 'grad_norm': 3.9746387004852295, 'learning_rate': 3.7431693989071045e-05, 'epoch': 1.26}\n",
      "{'loss': 2.5315, 'grad_norm': 3.790135145187378, 'learning_rate': 3.71584699453552e-05, 'epoch': 1.28}\n",
      "{'loss': 2.579, 'grad_norm': 2.998952627182007, 'learning_rate': 3.6885245901639346e-05, 'epoch': 1.31}\n",
      "{'loss': 2.6753, 'grad_norm': 4.887899875640869, 'learning_rate': 3.66120218579235e-05, 'epoch': 1.34}\n",
      "{'loss': 2.5426, 'grad_norm': 5.211826324462891, 'learning_rate': 3.633879781420765e-05, 'epoch': 1.37}\n",
      "{'loss': 2.6364, 'grad_norm': 4.341058731079102, 'learning_rate': 3.6065573770491806e-05, 'epoch': 1.39}\n",
      "{'loss': 2.5567, 'grad_norm': 3.1664721965789795, 'learning_rate': 3.579234972677596e-05, 'epoch': 1.42}\n",
      "{'loss': 2.5387, 'grad_norm': 3.591377019882202, 'learning_rate': 3.551912568306011e-05, 'epoch': 1.45}\n",
      "{'loss': 2.4916, 'grad_norm': 3.593461513519287, 'learning_rate': 3.524590163934427e-05, 'epoch': 1.48}\n",
      "{'loss': 2.6271, 'grad_norm': 5.2485127449035645, 'learning_rate': 3.4972677595628414e-05, 'epoch': 1.5}\n",
      "{'loss': 2.5188, 'grad_norm': 3.1898727416992188, 'learning_rate': 3.469945355191257e-05, 'epoch': 1.53}\n",
      "{'loss': 2.5307, 'grad_norm': 7.063162326812744, 'learning_rate': 3.442622950819672e-05, 'epoch': 1.56}\n",
      "{'loss': 2.6024, 'grad_norm': 6.405568599700928, 'learning_rate': 3.4153005464480874e-05, 'epoch': 1.58}\n",
      "{'loss': 2.651, 'grad_norm': 4.677648544311523, 'learning_rate': 3.387978142076503e-05, 'epoch': 1.61}\n",
      "{'loss': 2.5513, 'grad_norm': 3.7155373096466064, 'learning_rate': 3.360655737704918e-05, 'epoch': 1.64}\n",
      "{'loss': 2.6512, 'grad_norm': 3.9122118949890137, 'learning_rate': 3.3333333333333335e-05, 'epoch': 1.67}\n",
      "{'loss': 2.4633, 'grad_norm': 3.963791847229004, 'learning_rate': 3.306010928961749e-05, 'epoch': 1.69}\n",
      "{'loss': 2.5143, 'grad_norm': 5.178737163543701, 'learning_rate': 3.2786885245901635e-05, 'epoch': 1.72}\n",
      "{'loss': 2.4846, 'grad_norm': 2.619051456451416, 'learning_rate': 3.251366120218579e-05, 'epoch': 1.75}\n",
      "{'loss': 2.5872, 'grad_norm': 3.7557003498077393, 'learning_rate': 3.224043715846995e-05, 'epoch': 1.78}\n",
      "{'loss': 2.5492, 'grad_norm': 3.632157802581787, 'learning_rate': 3.19672131147541e-05, 'epoch': 1.8}\n",
      "{'loss': 2.564, 'grad_norm': 3.982642650604248, 'learning_rate': 3.1693989071038256e-05, 'epoch': 1.83}\n",
      "{'loss': 2.5568, 'grad_norm': 4.219918251037598, 'learning_rate': 3.142076502732241e-05, 'epoch': 1.86}\n",
      "{'loss': 2.6188, 'grad_norm': 3.737818479537964, 'learning_rate': 3.114754098360656e-05, 'epoch': 1.89}\n",
      "{'loss': 2.6694, 'grad_norm': 2.5700201988220215, 'learning_rate': 3.087431693989071e-05, 'epoch': 1.91}\n",
      "{'loss': 2.5719, 'grad_norm': 4.722013473510742, 'learning_rate': 3.0601092896174864e-05, 'epoch': 1.94}\n",
      "{'loss': 2.5603, 'grad_norm': 4.013306617736816, 'learning_rate': 3.0327868852459017e-05, 'epoch': 1.97}\n",
      "{'loss': 2.5441, 'grad_norm': 3.843099594116211, 'learning_rate': 3.005464480874317e-05, 'epoch': 1.99}\n",
      "{'loss': 2.4613, 'grad_norm': 3.386054039001465, 'learning_rate': 2.9781420765027324e-05, 'epoch': 2.02}\n",
      "{'loss': 2.4785, 'grad_norm': 4.002464771270752, 'learning_rate': 2.9508196721311478e-05, 'epoch': 2.05}\n",
      "{'loss': 2.3916, 'grad_norm': 5.0838494300842285, 'learning_rate': 2.9234972677595628e-05, 'epoch': 2.08}\n",
      "{'loss': 2.3333, 'grad_norm': 4.042195796966553, 'learning_rate': 2.896174863387978e-05, 'epoch': 2.1}\n",
      "{'loss': 2.3975, 'grad_norm': 4.383592128753662, 'learning_rate': 2.8688524590163935e-05, 'epoch': 2.13}\n",
      "{'loss': 2.1974, 'grad_norm': 2.6056883335113525, 'learning_rate': 2.841530054644809e-05, 'epoch': 2.16}\n",
      "{'loss': 2.499, 'grad_norm': 8.09701919555664, 'learning_rate': 2.814207650273224e-05, 'epoch': 2.19}\n",
      "{'loss': 2.3892, 'grad_norm': 3.6341593265533447, 'learning_rate': 2.7868852459016392e-05, 'epoch': 2.21}\n",
      "{'loss': 2.4627, 'grad_norm': 5.104237079620361, 'learning_rate': 2.7595628415300546e-05, 'epoch': 2.24}\n",
      "{'loss': 2.3846, 'grad_norm': 4.3764729499816895, 'learning_rate': 2.7322404371584703e-05, 'epoch': 2.27}\n",
      "{'loss': 2.4446, 'grad_norm': 4.316962242126465, 'learning_rate': 2.7049180327868856e-05, 'epoch': 2.3}\n",
      "{'loss': 2.4625, 'grad_norm': 3.336223602294922, 'learning_rate': 2.677595628415301e-05, 'epoch': 2.32}\n",
      "{'loss': 2.282, 'grad_norm': 7.533410549163818, 'learning_rate': 2.650273224043716e-05, 'epoch': 2.35}\n",
      "{'loss': 2.302, 'grad_norm': 6.806859493255615, 'learning_rate': 2.6229508196721314e-05, 'epoch': 2.38}\n",
      "{'loss': 2.4679, 'grad_norm': 5.679004192352295, 'learning_rate': 2.5956284153005467e-05, 'epoch': 2.4}\n",
      "{'loss': 2.3687, 'grad_norm': 4.0421013832092285, 'learning_rate': 2.568306010928962e-05, 'epoch': 2.43}\n",
      "{'loss': 2.3243, 'grad_norm': 7.544795513153076, 'learning_rate': 2.540983606557377e-05, 'epoch': 2.46}\n",
      "{'loss': 2.3922, 'grad_norm': 5.131463527679443, 'learning_rate': 2.5136612021857924e-05, 'epoch': 2.49}\n",
      "{'loss': 2.2835, 'grad_norm': 3.3656647205352783, 'learning_rate': 2.4863387978142078e-05, 'epoch': 2.51}\n",
      "{'loss': 2.3041, 'grad_norm': 4.5185441970825195, 'learning_rate': 2.459016393442623e-05, 'epoch': 2.54}\n",
      "{'loss': 2.3089, 'grad_norm': 4.315521240234375, 'learning_rate': 2.431693989071038e-05, 'epoch': 2.57}\n",
      "{'loss': 2.3248, 'grad_norm': 8.30019760131836, 'learning_rate': 2.4043715846994535e-05, 'epoch': 2.6}\n",
      "{'loss': 2.5271, 'grad_norm': 3.815308094024658, 'learning_rate': 2.377049180327869e-05, 'epoch': 2.62}\n",
      "{'loss': 2.4576, 'grad_norm': 4.7117815017700195, 'learning_rate': 2.3497267759562842e-05, 'epoch': 2.65}\n",
      "{'loss': 2.2292, 'grad_norm': 3.3926138877868652, 'learning_rate': 2.3224043715846996e-05, 'epoch': 2.68}\n",
      "{'loss': 2.4677, 'grad_norm': 4.311869144439697, 'learning_rate': 2.295081967213115e-05, 'epoch': 2.7}\n",
      "{'loss': 2.4204, 'grad_norm': 5.632282257080078, 'learning_rate': 2.2677595628415303e-05, 'epoch': 2.73}\n",
      "{'loss': 2.2493, 'grad_norm': 3.408618688583374, 'learning_rate': 2.2404371584699453e-05, 'epoch': 2.76}\n",
      "{'loss': 2.2727, 'grad_norm': 4.579395294189453, 'learning_rate': 2.2131147540983607e-05, 'epoch': 2.79}\n",
      "{'loss': 2.3056, 'grad_norm': 3.7770304679870605, 'learning_rate': 2.185792349726776e-05, 'epoch': 2.81}\n",
      "{'loss': 2.3722, 'grad_norm': 3.134049415588379, 'learning_rate': 2.1584699453551914e-05, 'epoch': 2.84}\n",
      "{'loss': 2.291, 'grad_norm': 4.27353572845459, 'learning_rate': 2.1311475409836064e-05, 'epoch': 2.87}\n",
      "{'loss': 2.3985, 'grad_norm': 3.679025888442993, 'learning_rate': 2.103825136612022e-05, 'epoch': 2.9}\n",
      "{'loss': 2.3499, 'grad_norm': 4.027650356292725, 'learning_rate': 2.0765027322404374e-05, 'epoch': 2.92}\n",
      "{'loss': 2.3346, 'grad_norm': 5.602505207061768, 'learning_rate': 2.0491803278688525e-05, 'epoch': 2.95}\n",
      "{'loss': 2.3238, 'grad_norm': 4.011843681335449, 'learning_rate': 2.0218579234972678e-05, 'epoch': 2.98}\n",
      "{'loss': 2.4419, 'grad_norm': 5.860108852386475, 'learning_rate': 1.994535519125683e-05, 'epoch': 3.01}\n",
      "{'loss': 2.2534, 'grad_norm': 3.7750396728515625, 'learning_rate': 1.9672131147540985e-05, 'epoch': 3.03}\n",
      "{'loss': 2.2196, 'grad_norm': 4.710107326507568, 'learning_rate': 1.9398907103825135e-05, 'epoch': 3.06}\n",
      "{'loss': 2.2626, 'grad_norm': 5.501427173614502, 'learning_rate': 1.912568306010929e-05, 'epoch': 3.09}\n",
      "{'loss': 2.1947, 'grad_norm': 2.770214080810547, 'learning_rate': 1.8852459016393442e-05, 'epoch': 3.11}\n",
      "{'loss': 2.2825, 'grad_norm': 6.0090508460998535, 'learning_rate': 1.85792349726776e-05, 'epoch': 3.14}\n",
      "{'loss': 2.1824, 'grad_norm': 5.5205302238464355, 'learning_rate': 1.830601092896175e-05, 'epoch': 3.17}\n",
      "{'loss': 2.2358, 'grad_norm': 4.161123275756836, 'learning_rate': 1.8032786885245903e-05, 'epoch': 3.2}\n",
      "{'loss': 2.0339, 'grad_norm': 5.670960426330566, 'learning_rate': 1.7759562841530057e-05, 'epoch': 3.22}\n",
      "{'loss': 2.2502, 'grad_norm': 4.282919883728027, 'learning_rate': 1.7486338797814207e-05, 'epoch': 3.25}\n",
      "{'loss': 2.2148, 'grad_norm': 6.75356388092041, 'learning_rate': 1.721311475409836e-05, 'epoch': 3.28}\n",
      "{'loss': 2.3158, 'grad_norm': 4.58829927444458, 'learning_rate': 1.6939890710382514e-05, 'epoch': 3.31}\n",
      "{'loss': 2.2511, 'grad_norm': 3.9379560947418213, 'learning_rate': 1.6666666666666667e-05, 'epoch': 3.33}\n",
      "{'loss': 2.2501, 'grad_norm': 5.5130438804626465, 'learning_rate': 1.6393442622950818e-05, 'epoch': 3.36}\n",
      "{'loss': 2.2125, 'grad_norm': 3.5911083221435547, 'learning_rate': 1.6120218579234975e-05, 'epoch': 3.39}\n",
      "{'loss': 2.1767, 'grad_norm': 5.348552703857422, 'learning_rate': 1.5846994535519128e-05, 'epoch': 3.42}\n",
      "{'loss': 2.2639, 'grad_norm': 3.5626442432403564, 'learning_rate': 1.557377049180328e-05, 'epoch': 3.44}\n",
      "{'loss': 2.0912, 'grad_norm': 4.933493137359619, 'learning_rate': 1.5300546448087432e-05, 'epoch': 3.47}\n",
      "{'loss': 2.169, 'grad_norm': 4.0533223152160645, 'learning_rate': 1.5027322404371585e-05, 'epoch': 3.5}\n",
      "{'loss': 2.2171, 'grad_norm': 6.699529647827148, 'learning_rate': 1.4754098360655739e-05, 'epoch': 3.52}\n",
      "{'loss': 2.1344, 'grad_norm': 4.1351728439331055, 'learning_rate': 1.448087431693989e-05, 'epoch': 3.55}\n",
      "{'loss': 2.329, 'grad_norm': 4.425739288330078, 'learning_rate': 1.4207650273224044e-05, 'epoch': 3.58}\n",
      "{'loss': 2.1507, 'grad_norm': 4.667265892028809, 'learning_rate': 1.3934426229508196e-05, 'epoch': 3.61}\n",
      "{'loss': 2.3056, 'grad_norm': 7.444682598114014, 'learning_rate': 1.3661202185792351e-05, 'epoch': 3.63}\n",
      "{'loss': 2.1829, 'grad_norm': 3.0057008266448975, 'learning_rate': 1.3387978142076505e-05, 'epoch': 3.66}\n",
      "{'loss': 2.2384, 'grad_norm': 3.8145241737365723, 'learning_rate': 1.3114754098360657e-05, 'epoch': 3.69}\n",
      "{'loss': 2.1392, 'grad_norm': 5.159133434295654, 'learning_rate': 1.284153005464481e-05, 'epoch': 3.72}\n",
      "{'loss': 2.2573, 'grad_norm': 8.251238822937012, 'learning_rate': 1.2568306010928962e-05, 'epoch': 3.74}\n",
      "{'loss': 2.1841, 'grad_norm': 5.311625957489014, 'learning_rate': 1.2295081967213116e-05, 'epoch': 3.77}\n",
      "{'loss': 2.1238, 'grad_norm': 7.7386908531188965, 'learning_rate': 1.2021857923497268e-05, 'epoch': 3.8}\n",
      "{'loss': 2.1977, 'grad_norm': 7.701966762542725, 'learning_rate': 1.1748633879781421e-05, 'epoch': 3.83}\n",
      "{'loss': 2.2238, 'grad_norm': 4.216488838195801, 'learning_rate': 1.1475409836065575e-05, 'epoch': 3.85}\n",
      "{'loss': 2.274, 'grad_norm': 4.967339038848877, 'learning_rate': 1.1202185792349727e-05, 'epoch': 3.88}\n",
      "{'loss': 2.3138, 'grad_norm': 3.8881256580352783, 'learning_rate': 1.092896174863388e-05, 'epoch': 3.91}\n",
      "{'loss': 2.2237, 'grad_norm': 7.313974380493164, 'learning_rate': 1.0655737704918032e-05, 'epoch': 3.93}\n",
      "{'loss': 2.2751, 'grad_norm': 3.2934257984161377, 'learning_rate': 1.0382513661202187e-05, 'epoch': 3.96}\n",
      "{'loss': 2.3841, 'grad_norm': 6.527979373931885, 'learning_rate': 1.0109289617486339e-05, 'epoch': 3.99}\n",
      "{'loss': 2.1141, 'grad_norm': 5.287485122680664, 'learning_rate': 9.836065573770493e-06, 'epoch': 4.02}\n",
      "{'loss': 2.1553, 'grad_norm': 4.283511161804199, 'learning_rate': 9.562841530054644e-06, 'epoch': 4.04}\n",
      "{'loss': 2.1669, 'grad_norm': 7.603151798248291, 'learning_rate': 9.2896174863388e-06, 'epoch': 4.07}\n",
      "{'loss': 2.2265, 'grad_norm': 4.3215413093566895, 'learning_rate': 9.016393442622952e-06, 'epoch': 4.1}\n",
      "{'loss': 2.0152, 'grad_norm': 5.925968647003174, 'learning_rate': 8.743169398907103e-06, 'epoch': 4.13}\n",
      "{'loss': 2.0783, 'grad_norm': 3.938143730163574, 'learning_rate': 8.469945355191257e-06, 'epoch': 4.15}\n",
      "{'loss': 2.3344, 'grad_norm': 5.5084099769592285, 'learning_rate': 8.196721311475409e-06, 'epoch': 4.18}\n",
      "{'loss': 2.0688, 'grad_norm': 7.957108020782471, 'learning_rate': 7.923497267759564e-06, 'epoch': 4.21}\n",
      "{'loss': 2.0481, 'grad_norm': 4.62318754196167, 'learning_rate': 7.650273224043716e-06, 'epoch': 4.23}\n",
      "{'loss': 2.1526, 'grad_norm': 4.912319660186768, 'learning_rate': 7.3770491803278695e-06, 'epoch': 4.26}\n",
      "{'loss': 2.0944, 'grad_norm': 5.608911037445068, 'learning_rate': 7.103825136612022e-06, 'epoch': 4.29}\n",
      "{'loss': 2.1, 'grad_norm': 3.8520798683166504, 'learning_rate': 6.830601092896176e-06, 'epoch': 4.32}\n",
      "{'loss': 2.1483, 'grad_norm': 4.866466999053955, 'learning_rate': 6.557377049180328e-06, 'epoch': 4.34}\n",
      "{'loss': 2.1776, 'grad_norm': 4.2665181159973145, 'learning_rate': 6.284153005464481e-06, 'epoch': 4.37}\n",
      "{'loss': 2.0674, 'grad_norm': 4.51029634475708, 'learning_rate': 6.010928961748634e-06, 'epoch': 4.4}\n",
      "{'loss': 2.164, 'grad_norm': 3.590599775314331, 'learning_rate': 5.737704918032787e-06, 'epoch': 4.43}\n",
      "{'loss': 2.0863, 'grad_norm': 5.368654251098633, 'learning_rate': 5.46448087431694e-06, 'epoch': 4.45}\n",
      "{'loss': 2.1331, 'grad_norm': 3.5720736980438232, 'learning_rate': 5.191256830601094e-06, 'epoch': 4.48}\n",
      "{'loss': 2.0467, 'grad_norm': 3.4748477935791016, 'learning_rate': 4.918032786885246e-06, 'epoch': 4.51}\n",
      "{'loss': 2.0432, 'grad_norm': 4.071724891662598, 'learning_rate': 4.6448087431694e-06, 'epoch': 4.54}\n",
      "{'loss': 2.1559, 'grad_norm': 4.411365985870361, 'learning_rate': 4.371584699453552e-06, 'epoch': 4.56}\n",
      "{'loss': 2.2208, 'grad_norm': 3.980766773223877, 'learning_rate': 4.098360655737704e-06, 'epoch': 4.59}\n",
      "{'loss': 2.0644, 'grad_norm': 4.479823112487793, 'learning_rate': 3.825136612021858e-06, 'epoch': 4.62}\n",
      "{'loss': 2.0542, 'grad_norm': 6.370019435882568, 'learning_rate': 3.551912568306011e-06, 'epoch': 4.64}\n",
      "{'loss': 2.1014, 'grad_norm': 3.892443895339966, 'learning_rate': 3.278688524590164e-06, 'epoch': 4.67}\n",
      "{'loss': 2.1355, 'grad_norm': 7.333188056945801, 'learning_rate': 3.005464480874317e-06, 'epoch': 4.7}\n",
      "{'loss': 2.1463, 'grad_norm': 6.162367343902588, 'learning_rate': 2.73224043715847e-06, 'epoch': 4.73}\n",
      "{'loss': 2.1351, 'grad_norm': 5.302271842956543, 'learning_rate': 2.459016393442623e-06, 'epoch': 4.75}\n",
      "{'loss': 2.1005, 'grad_norm': 5.835043430328369, 'learning_rate': 2.185792349726776e-06, 'epoch': 4.78}\n",
      "{'loss': 2.0729, 'grad_norm': 3.943864345550537, 'learning_rate': 1.912568306010929e-06, 'epoch': 4.81}\n",
      "{'loss': 2.0651, 'grad_norm': 5.255500316619873, 'learning_rate': 1.639344262295082e-06, 'epoch': 4.84}\n",
      "{'loss': 2.148, 'grad_norm': 5.336105823516846, 'learning_rate': 1.366120218579235e-06, 'epoch': 4.86}\n",
      "{'loss': 2.2553, 'grad_norm': 4.979359149932861, 'learning_rate': 1.092896174863388e-06, 'epoch': 4.89}\n",
      "{'loss': 2.2299, 'grad_norm': 6.135898113250732, 'learning_rate': 8.19672131147541e-07, 'epoch': 4.92}\n",
      "{'loss': 2.1463, 'grad_norm': 6.467000961303711, 'learning_rate': 5.46448087431694e-07, 'epoch': 4.95}\n",
      "{'loss': 2.132, 'grad_norm': 3.037583589553833, 'learning_rate': 2.73224043715847e-07, 'epoch': 4.97}\n",
      "{'loss': 2.1147, 'grad_norm': 8.332460403442383, 'learning_rate': 0.0, 'epoch': 5.0}\n",
      "{'train_runtime': 2347.904, 'train_samples_per_second': 15.586, 'train_steps_per_second': 7.794, 'train_loss': 2.4482092985559682, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=18300, training_loss=2.4482092985559682, metrics={'train_runtime': 2347.904, 'train_samples_per_second': 15.586, 'train_steps_per_second': 7.794, 'total_flos': 4780638823680000.0, 'train_loss': 2.4482092985559682, 'epoch': 5.0})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size=2,\n",
    "    save_steps=10_000,\n",
    "    save_total_limit=2,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=100,\n",
    "    report_to=\"comet_ml\",  # Ensure training logs are sent to Comet\n",
    ")\n",
    "\n",
    "# Instantiate Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=tokenized_train_dataset,\n",
    "    #eval_dataset=tokenized_test_dataset,\n",
    "    compute_metrics=None,  # Add compute_metrics function if needed\n",
    ")\n",
    "\n",
    "# Fine-tune the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./fine_tuned_rap_model\\\\tokenizer_config.json',\n",
       " './fine_tuned_rap_model\\\\special_tokens_map.json',\n",
       " './fine_tuned_rap_model\\\\vocab.json',\n",
       " './fine_tuned_rap_model\\\\merges.txt',\n",
       " './fine_tuned_rap_model\\\\added_tokens.json',\n",
       " './fine_tuned_rap_model\\\\tokenizer.json')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the fine-tuned model\n",
    "model.save_pretrained('./fine_tuned_rap_model')\n",
    "tokenizer.save_pretrained('./fine_tuned_rap_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics = trainer.evaluate(eval_dataset=tokenized_test_dataset)\n",
    "# experiment.log_metrics(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml Experiment Summary\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     name                  : practical_hearth_893\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : https://www.comet.com/artaasd95/rap-lyrics-generator-llm/cc4cab51aa9944e1a4e6f8dcd45a3d30\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Metrics [count] (min, max):\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     loss [1830]                    : (0.29766061902046204, 4.7499237060546875)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/epoch [184]              : (0.0273224043715847, 5.0)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/grad_norm [183]          : (2.5700201988220215, 15.812793731689453)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/learning_rate [183]      : (0.0, 4.9726775956284156e-05)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/loss [183]               : (2.0152, 3.2603)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/total_flos               : 4780638823680000.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/train_loss               : 2.4482092985559682\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/train_runtime            : 2347.904\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/train_samples_per_second : 15.586\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/train_steps_per_second   : 7.794\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Others:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hasNestedParams : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Parameters:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|accelerator_config|dispatch_batches               : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|accelerator_config|even_batches                   : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|accelerator_config|gradient_accumulation_kwargs   : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|accelerator_config|non_blocking                   : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|accelerator_config|split_batches                  : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|accelerator_config|use_seedable_sampler           : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|adafactor                                         : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|adam_beta1                                        : 0.9\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|adam_beta2                                        : 0.999\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|adam_epsilon                                      : 1e-08\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|auto_find_batch_size                              : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|batch_eval_metrics                                : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|bf16                                              : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|bf16_full_eval                                    : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|data_seed                                         : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|dataloader_drop_last                              : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|dataloader_num_workers                            : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|dataloader_persistent_workers                     : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|dataloader_pin_memory                             : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|dataloader_prefetch_factor                        : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|ddp_backend                                       : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|ddp_broadcast_buffers                             : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|ddp_bucket_cap_mb                                 : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|ddp_find_unused_parameters                        : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|ddp_timeout                                       : 1800\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|debug                                             : []\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|deepspeed                                         : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|disable_tqdm                                      : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|dispatch_batches                                  : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|do_eval                                           : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|do_predict                                        : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|do_train                                          : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|eval_accumulation_steps                           : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|eval_delay                                        : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|eval_do_concat_batches                            : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|eval_on_start                                     : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|eval_steps                                        : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|eval_strategy                                     : no\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|eval_use_gather_object                            : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|evaluation_strategy                               : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|fp16                                              : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|fp16_backend                                      : auto\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|fp16_full_eval                                    : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|fp16_opt_level                                    : O1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|fsdp                                              : []\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|fsdp_config|min_num_params                        : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|fsdp_config|xla                                   : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|fsdp_config|xla_fsdp_grad_ckpt                    : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|fsdp_config|xla_fsdp_v2                           : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|fsdp_min_num_params                               : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|fsdp_transformer_layer_cls_to_wrap                : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|full_determinism                                  : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|gradient_accumulation_steps                       : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|gradient_checkpointing                            : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|gradient_checkpointing_kwargs                     : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|greater_is_better                                 : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|group_by_length                                   : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|half_precision_backend                            : auto\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|hub_always_push                                   : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|hub_model_id                                      : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|hub_private_repo                                  : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|hub_strategy                                      : every_save\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|hub_token                                         : <HUB_TOKEN>\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|ignore_data_skip                                  : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|include_for_metrics                               : []\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|include_inputs_for_metrics                        : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|include_num_input_tokens_seen                     : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|include_tokens_per_second                         : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|jit_mode_eval                                     : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|label_names                                       : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|label_smoothing_factor                            : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|learning_rate                                     : 5e-05\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|length_column_name                                : length\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|load_best_model_at_end                            : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|local_rank                                        : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|log_level                                         : passive\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|log_level_replica                                 : warning\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|log_on_each_node                                  : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|logging_dir                                       : ./logs\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|logging_first_step                                : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|logging_nan_inf_filter                            : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|logging_steps                                     : 100\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|logging_strategy                                  : steps\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|lr_scheduler_kwargs                               : {}\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|lr_scheduler_type                                 : linear\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|max_grad_norm                                     : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|max_steps                                         : -1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|metric_for_best_model                             : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|mp_parameters                                     : \n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|neftune_noise_alpha                               : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|no_cuda                                           : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|num_train_epochs                                  : 5\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|optim                                             : adamw_torch\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|optim_args                                        : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|optim_target_modules                              : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|output_dir                                        : ./results\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|overwrite_output_dir                              : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|past_index                                        : -1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|per_device_eval_batch_size                        : 8\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|per_device_train_batch_size                       : 2\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|per_gpu_eval_batch_size                           : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|per_gpu_train_batch_size                          : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|prediction_loss_only                              : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|push_to_hub                                       : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|push_to_hub_model_id                              : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|push_to_hub_organization                          : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|push_to_hub_token                                 : <PUSH_TO_HUB_TOKEN>\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|ray_scope                                         : last\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|remove_unused_columns                             : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|report_to                                         : ['comet_ml']\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|restore_callback_states_from_checkpoint           : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|resume_from_checkpoint                            : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|run_name                                          : ./results\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|save_on_each_node                                 : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|save_only_model                                   : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|save_safetensors                                  : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|save_steps                                        : 10000\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|save_strategy                                     : steps\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|save_total_limit                                  : 2\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|seed                                              : 42\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|skip_memory_metrics                               : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|split_batches                                     : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|tf32                                              : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|torch_compile                                     : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|torch_compile_backend                             : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|torch_compile_mode                                : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|torch_empty_cache_steps                           : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|torchdynamo                                       : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|tpu_metrics_debug                                 : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|tpu_num_cores                                     : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|use_cpu                                           : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|use_ipex                                          : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|use_legacy_prediction_loop                        : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|use_liger_kernel                                  : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|use_mps_device                                    : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|warmup_ratio                                      : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|warmup_steps                                      : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args|weight_decay                                      : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|_attn_implementation_autoset                    : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|_name_or_path                                   : gpt2\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|activation_function                             : gelu_new\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|add_cross_attention                             : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|architectures                                   : ['GPT2LMHeadModel']\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|attn_pdrop                                      : 0.1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|bad_words_ids                                   : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|begin_suppress_tokens                           : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|bos_token_id                                    : 50256\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|chunk_size_feed_forward                         : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|cross_attention_hidden_size                     : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|decoder_start_token_id                          : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|diversity_penalty                               : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|do_sample                                       : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|early_stopping                                  : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|embd_pdrop                                      : 0.1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|encoder_no_repeat_ngram_size                    : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|eos_token_id                                    : 50256\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|exponential_decay_length_penalty                : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|finetuning_task                                 : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|forced_bos_token_id                             : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|forced_eos_token_id                             : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|id2label|0                                      : LABEL_0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|id2label|1                                      : LABEL_1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|initializer_range                               : 0.02\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|is_decoder                                      : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|is_encoder_decoder                              : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|label2id|LABEL_0                                : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|label2id|LABEL_1                                : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|layer_norm_epsilon                              : 1e-05\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|length_penalty                                  : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|max_length                                      : 20\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|min_length                                      : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|model_type                                      : gpt2\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|n_ctx                                           : 1024\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|n_embd                                          : 768\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|n_head                                          : 12\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|n_inner                                         : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|n_layer                                         : 12\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|n_positions                                     : 1024\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|no_repeat_ngram_size                            : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|num_beam_groups                                 : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|num_beams                                       : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|num_return_sequences                            : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|output_attentions                               : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|output_hidden_states                            : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|output_scores                                   : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|pad_token_id                                    : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|prefix                                          : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|problem_type                                    : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|pruned_heads                                    : {}\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|remove_invalid_values                           : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|reorder_and_upcast_attn                         : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|repetition_penalty                              : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|resid_pdrop                                     : 0.1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|return_dict                                     : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|return_dict_in_generate                         : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|scale_attn_by_inverse_layer_idx                 : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|scale_attn_weights                              : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|sep_token_id                                    : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|summary_activation                              : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|summary_first_dropout                           : 0.1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|summary_proj_to_labels                          : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|summary_type                                    : cls_index\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|summary_use_proj                                : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|suppress_tokens                                 : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|task_specific_params|text-generation|do_sample  : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|task_specific_params|text-generation|max_length : 50\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|temperature                                     : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|tf_legacy_loss                                  : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|tie_encoder_decoder                             : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|tie_word_embeddings                             : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|tokenizer_class                                 : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|top_k                                           : 50\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|top_p                                           : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|torch_dtype                                     : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|torchscript                                     : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|transformers_version                            : 4.46.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|typical_p                                       : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|use_bfloat16                                    : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|use_cache                                       : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config|vocab_size                                      : 50258\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     num_train_epochs                                       : 5\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     per_device_train_batch_size                            : 2\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Uploads:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     environment details : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     filename            : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     git metadata        : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     installed packages  : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model graph         : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     notebook            : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source_code         : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m \n"
     ]
    }
   ],
   "source": [
    "experiment.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
